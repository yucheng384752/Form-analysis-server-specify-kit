"""add_p1_p2_p3_data_types

Revision ID: d0c4b28c0776
Revises: ae889647f4f2
Create Date: 2025-11-10 01:10:21.911181

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'd0c4b28c0776'
down_revision: Union[str, Sequence[str], None] = 'ae889647f4f2'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('analysis_results', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_analysis_results_field_name'))
        batch_op.drop_index(batch_op.f('idx_analysis_results_form_id'))

    op.drop_table('analysis_results')
    with op.batch_alter_table('forms', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_forms_filename'))
        batch_op.drop_index(batch_op.f('idx_forms_processing_status'))
        batch_op.drop_index(batch_op.f('idx_forms_upload_time'))

    op.drop_table('forms')
    with op.batch_alter_table('records', schema=None) as batch_op:
        batch_op.add_column(sa.Column('data_type', sa.Enum('P1', 'P2', 'P3', name='data_type_enum'), nullable=True, comment='資料類型：P1(產品基本資料), P2(尺寸檢測資料), P3(追蹤編號)'))
    
    # 為現有記錄設置默認資料類型為 P1
    op.execute("UPDATE records SET data_type = 'P1' WHERE data_type IS NULL")
    
    # 將 data_type 設為非空
    with op.batch_alter_table('records', schema=None) as batch_op:
        batch_op.alter_column('data_type', nullable=False)
        batch_op.add_column(sa.Column('notes', sa.Text(), nullable=True, comment='備註 (P1/P3使用)'))
        batch_op.add_column(sa.Column('p3_no', sa.String(length=50), nullable=True, comment='P3追蹤編號 (P3使用)'))
        batch_op.add_column(sa.Column('sheet_width', sa.Float(), nullable=True, comment='片材寬度(mm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness1', sa.Float(), nullable=True, comment='厚度1(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness2', sa.Float(), nullable=True, comment='厚度2(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness3', sa.Float(), nullable=True, comment='厚度3(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness4', sa.Float(), nullable=True, comment='厚度4(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness5', sa.Float(), nullable=True, comment='厚度5(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness6', sa.Float(), nullable=True, comment='厚度6(μm) (P2使用)'))
        batch_op.add_column(sa.Column('thickness7', sa.Float(), nullable=True, comment='厚度7(μm) (P2使用)'))
        batch_op.add_column(sa.Column('appearance', sa.Integer(), nullable=True, comment='外觀 (P2使用，0或1)'))
        batch_op.add_column(sa.Column('rough_edge', sa.Integer(), nullable=True, comment='粗糙邊緣 (P2使用，0或1)'))
        batch_op.add_column(sa.Column('slitting_result', sa.Integer(), nullable=True, comment='切割結果 (P2使用，0或1)'))
        batch_op.add_column(sa.Column('additional_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True, comment='額外資料，JSONB格式'))
        batch_op.alter_column('production_date',
               existing_type=sa.DATE(),
               nullable=True,
               existing_comment='生產日期，格式：YYYY-MM-DD')
        batch_op.alter_column('product_name',
               existing_type=sa.VARCHAR(length=100),
               nullable=True,
               comment='產品名稱 (P1/P3使用)',
               existing_comment='產品名稱，1-100字元')
        batch_op.alter_column('quantity',
               existing_type=sa.INTEGER(),
               nullable=True,
               comment='數量 (P1/P3使用)',
               existing_comment='數量，非負整數')
        batch_op.create_index('ix_records_data_type', ['data_type'], unique=False, postgresql_using='btree')
        batch_op.create_index('ix_records_lot_no_data_type', ['lot_no', 'data_type'], unique=False, postgresql_using='btree')

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('records', schema=None) as batch_op:
        batch_op.drop_index('ix_records_lot_no_data_type', postgresql_using='btree')
        batch_op.drop_index('ix_records_data_type', postgresql_using='btree')
        batch_op.alter_column('quantity',
               existing_type=sa.INTEGER(),
               nullable=False,
               comment='數量，非負整數',
               existing_comment='數量 (P1/P3使用)')
        batch_op.alter_column('product_name',
               existing_type=sa.VARCHAR(length=100),
               nullable=False,
               comment='產品名稱，1-100字元',
               existing_comment='產品名稱 (P1/P3使用)')
        batch_op.alter_column('production_date',
               existing_type=sa.DATE(),
               nullable=False,
               existing_comment='生產日期，格式：YYYY-MM-DD')
        batch_op.drop_column('additional_data')
        batch_op.drop_column('slitting_result')
        batch_op.drop_column('rough_edge')
        batch_op.drop_column('appearance')
        batch_op.drop_column('thickness7')
        batch_op.drop_column('thickness6')
        batch_op.drop_column('thickness5')
        batch_op.drop_column('thickness4')
        batch_op.drop_column('thickness3')
        batch_op.drop_column('thickness2')
        batch_op.drop_column('thickness1')
        batch_op.drop_column('sheet_width')
        batch_op.drop_column('p3_no')
        batch_op.drop_column('notes')
        batch_op.drop_column('data_type')

    op.create_table('forms',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('original_filename', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('file_size', sa.BIGINT(), autoincrement=False, nullable=False),
    sa.Column('file_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('upload_time', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('processing_status', sa.VARCHAR(length=50), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=True),
    sa.Column('analysis_result', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name='forms_pkey'),
    postgresql_ignore_search_path=False
    )
    with op.batch_alter_table('forms', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_forms_upload_time'), ['upload_time'], unique=False)
        batch_op.create_index(batch_op.f('idx_forms_processing_status'), ['processing_status'], unique=False)
        batch_op.create_index(batch_op.f('idx_forms_filename'), ['filename'], unique=False)

    op.create_table('analysis_results',
    sa.Column('id', sa.UUID(), server_default=sa.text('uuid_generate_v4()'), autoincrement=False, nullable=False),
    sa.Column('form_id', sa.UUID(), autoincrement=False, nullable=True),
    sa.Column('field_name', sa.VARCHAR(length=255), autoincrement=False, nullable=True),
    sa.Column('field_type', sa.VARCHAR(length=100), autoincrement=False, nullable=True),
    sa.Column('field_value', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.NUMERIC(precision=5, scale=4), autoincrement=False, nullable=True),
    sa.Column('bounding_box', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['form_id'], ['forms.id'], name=op.f('analysis_results_form_id_fkey'), ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name=op.f('analysis_results_pkey'))
    )
    with op.batch_alter_table('analysis_results', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_analysis_results_form_id'), ['form_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_analysis_results_field_name'), ['field_name'], unique=False)

    # ### end Alembic commands ###
