# Implementation Plan: è¡¨å–®ä¸Šå‚³é©—è­‰ç³»çµ± MVP

**Branch**: `master` | **Date**: 2025-11-08 | **Spec**: [spec.md](./spec.md)
**Input**: æª”æ¡ˆä¸Šå‚³ + é©—è­‰ + é è¦½ + åŒ¯å…¥ç³»çµ±è¦æ ¼

## Summary

å»ºç«‹æœ€å°å¯è¡Œçš„æª”æ¡ˆè™•ç†ç³»çµ±ï¼Œæ”¯æ´ CSV/Excel ä¸Šå‚³ã€å³æ™‚é©—è­‰ã€è³‡æ–™é è¦½èˆ‡æ‰¹æ¬¡åŒ¯å…¥ã€‚æ¡ç”¨å‰å¾Œç«¯åˆ†é›¢æ¶æ§‹ï¼Œå¾Œç«¯ FastAPI + PostgreSQLï¼Œå‰ç«¯ React + TypeScriptï¼Œé€é Docker Compose çµ±ä¸€éƒ¨ç½²ã€‚æ ¸å¿ƒæµç¨‹ï¼šä¸Šå‚³ â†’ é©—è­‰ â†’ é è¦½ â†’ ç¢ºèªåŒ¯å…¥ï¼Œæ¯æ­¥é©Ÿæä¾›æ¸…æ™°çš„ä½¿ç”¨è€…å›é¥‹èˆ‡éŒ¯èª¤è™•ç†ã€‚

## Technical Context

**Language/Version**: Python 3.12, TypeScript 5.x, Node.js 20+  
**Primary Dependencies**: FastAPI, Pydantic v2, SQLAlchemy 2.x, Alembic, React, Vite  
**Storage**: PostgreSQL 16 (containerized), file system (temporary upload storage)  
**Testing**: pytest + coverage (backend), vitest (frontend), pre-commit hooks  
**Target Platform**: Linux containers (Docker), modern browsers (Chrome 90+, Firefox 88+)  
**Project Type**: Web application (frontend + backend separation)  
**Performance Goals**: 3s é©—è­‰å›æ‡‰, 30s åŒ¯å…¥å®Œæˆ (10k ç­†), 10MB æª”æ¡ˆæ”¯æ´, 10 ä¸¦ç™¼ä½¿ç”¨è€…  
**Constraints**: 10MB æª”æ¡ˆä¸Šé™, ä¸­æ–‡å‹å–„éŒ¯èª¤, process_id è¿½è¹¤, äº¤æ˜“æ€§åŒ¯å…¥  
**Scale/Scope**: å…§éƒ¨å·¥å…· (~50 ä½¿ç”¨è€…), å–®ä¸€åŠŸèƒ½æ¨¡çµ„, MVP ç¯„åœ 4-5 API ç«¯é»

## Constitution Check

*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*

 **SDD æµç¨‹**: è¦æ ¼å·²å®Œæˆ â†’ æœ¬è¨ˆç•« â†’ ä»»å‹™åˆ†è§£ â†’ å¯¦ä½œ  
 **å‰å¾Œç«¯åˆ†é›¢**: FastAPI (å¾Œç«¯) + React (å‰ç«¯) + Docker Compose  
 **ç¨‹å¼ç¢¼å“è³ª**: ruff + black + mypy (Python), eslint + prettier (TS), pre-commit  
 **æ¸¬è©¦èˆ‡ CI**: pytest + vitest, GitHub Actions è¨­å®š lint â†’ test â†’ type-check  
 **å¯è§€æ¸¬æ€§**: ä¸­ä»‹å±¤è¨˜éŒ„ request_id, è™•ç†æ™‚é–“, éŒ¯èª¤è¿½è¹¤, çµæ§‹åŒ–æ—¥èªŒ  

**é€šéæ¢ä»¶**: æ‰€æœ‰å·¥å…·è¨­å®šèˆ‡ Docker ç’°å¢ƒç¬¦åˆæ†²ç« è¦æ±‚

## Project Structure

### Documentation (this feature)

```text
specs/[###-feature]/
â”œâ”€â”€ plan.md              # This file (/speckit.plan command output)
â”œâ”€â”€ research.md          # Phase 0 output (/speckit.plan command)
â”œâ”€â”€ data-model.md        # Phase 1 output (/speckit.plan command)
â”œâ”€â”€ quickstart.md        # Phase 1 output (/speckit.plan command)
â”œâ”€â”€ contracts/           # Phase 1 output (/speckit.plan command)
â””â”€â”€ tasks.md             # Phase 2 output (/speckit.tasks command - NOT created by /speckit.plan)
```

### Source Code (repository root)

```text
form-analysis-server/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI æ‡‰ç”¨ç¨‹å¼é€²å…¥é»
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_upload.py       # POST /api/upload (æª”æ¡ˆä¸Šå‚³+é©—è­‰)
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_validate.py     # GET /api/validate (å–è©³ç´°é©—è­‰çµæœ)
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_import.py       # POST /api/import (ç¢ºèªåŒ¯å…¥)
â”‚   â”‚   â”‚   â”œâ”€â”€ routes_export.py       # GET /api/export (ä¸‹è¼‰éŒ¯èª¤CSV)
â”‚   â”‚   â”‚   â””â”€â”€ routes_health.py       # GET /healthz
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py              # ç’°å¢ƒè®Šæ•¸èˆ‡è¨­å®š
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py            # SQLAlchemy é€£ç·šè¨­å®š
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py             # çµæ§‹åŒ–æ—¥èªŒé…ç½®
â”‚   â”‚   â”‚   â””â”€â”€ middleware.py          # request_id, æ™‚é–“è¨˜éŒ„ä¸­ä»‹å±¤
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ file_parser.py         # CSV/Excel è§£ææœå‹™
â”‚   â”‚   â”‚   â”œâ”€â”€ validator.py           # è³‡æ–™é©—è­‰æœå‹™
â”‚   â”‚   â”‚   â””â”€â”€ importer.py            # è³‡æ–™åŒ¯å…¥æœå‹™
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ upload_jobs.py         # ä¸Šå‚³å·¥ä½œè¨˜éŒ„
â”‚   â”‚   â”‚   â”œâ”€â”€ upload_errors.py       # é©—è­‰éŒ¯èª¤è¨˜éŒ„
â”‚   â”‚   â”‚   â””â”€â”€ records.py             # æ¥­å‹™è³‡æ–™æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.py              # ä¸Šå‚³ç›¸é—œ Pydantic models
â”‚   â”‚   â”‚   â”œâ”€â”€ validation.py          # é©—è­‰ç›¸é—œ Pydantic models
â”‚   â”‚   â”‚   â””â”€â”€ responses.py           # API å›æ‡‰æ ¼å¼
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ file_utils.py          # æª”æ¡ˆè™•ç†å·¥å…·å‡½æ•¸
â”‚   â”œâ”€â”€ alembic/
â”‚   â”‚   â”œâ”€â”€ versions/                  # migration æª”æ¡ˆ
â”‚   â”‚   â”œâ”€â”€ env.py                     # Alembic ç’°å¢ƒè¨­å®š
â”‚   â”‚   â””â”€â”€ script.py.mako             # migration æ¨¡æ¿
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ conftest.py                # pytest é…ç½®èˆ‡ fixtures
â”‚   â”‚   â”œâ”€â”€ unit/                      # å–®å…ƒæ¸¬è©¦
â”‚   â”‚   â”‚   â”œâ”€â”€ test_validator.py
â”‚   â”‚   â”‚   â”œâ”€â”€ test_file_parser.py
â”‚   â”‚   â”‚   â””â”€â”€ test_importer.py
â”‚   â”‚   â”œâ”€â”€ integration/               # æ•´åˆæ¸¬è©¦
â”‚   â”‚   â”‚   â”œâ”€â”€ test_upload_flow.py
â”‚   â”‚   â”‚   â””â”€â”€ test_database.py
â”‚   â”‚   â””â”€â”€ fixtures/                  # æ¸¬è©¦æª”æ¡ˆèˆ‡è³‡æ–™
â”‚   â”‚       â”œâ”€â”€ valid_sample.csv
â”‚   â”‚       â”œâ”€â”€ invalid_sample.csv
â”‚   â”‚       â””â”€â”€ sample.xlsx
â”‚   â”œâ”€â”€ pyproject.toml                 # Python å°ˆæ¡ˆé…ç½®
â”‚   â”œâ”€â”€ requirements.txt               # ä¾è³´å¥—ä»¶æ¸…å–®
â”‚   â””â”€â”€ Dockerfile                     # å¾Œç«¯å®¹å™¨é…ç½®
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Upload.tsx             # ä¸»è¦ä¸Šå‚³é é¢
â”‚   â”‚   â”‚   â”œâ”€â”€ Validation.tsx         # é©—è­‰çµæœé é¢
â”‚   â”‚   â”‚   â””â”€â”€ Import.tsx             # åŒ¯å…¥ç¢ºèªé é¢
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploader.tsx       # æª”æ¡ˆä¸Šå‚³å…ƒä»¶
â”‚   â”‚   â”‚   â”œâ”€â”€ PreviewTable.tsx       # è³‡æ–™é è¦½è¡¨æ ¼
â”‚   â”‚   â”‚   â”œâ”€â”€ ErrorList.tsx          # éŒ¯èª¤åˆ—è¡¨é¡¯ç¤º
â”‚   â”‚   â”‚   â””â”€â”€ ProgressBar.tsx        # é€²åº¦æ¢å…ƒä»¶
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â”œâ”€â”€ api.ts                 # API å‘¼å«å°è£
â”‚   â”‚   â”‚   â””â”€â”€ validation.ts          # å‰ç«¯é©—è­‰é‚è¼¯
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â”œâ”€â”€ upload.ts              # ä¸Šå‚³ç›¸é—œ TypeScript å‹åˆ¥
â”‚   â”‚   â”‚   â””â”€â”€ api.ts                 # API å›æ‡‰å‹åˆ¥å®šç¾©
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ file.ts                # æª”æ¡ˆè™•ç†å·¥å…·
â”‚   â”‚   â”œâ”€â”€ App.tsx                    # React ä¸»æ‡‰ç”¨
â”‚   â”‚   â””â”€â”€ main.tsx                   # æ‡‰ç”¨ç¨‹å¼é€²å…¥é»
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ components/                # å…ƒä»¶æ¸¬è©¦
â”‚   â”‚   â”œâ”€â”€ integration/               # ç«¯åˆ°ç«¯æ¸¬è©¦
â”‚   â”‚   â””â”€â”€ utils/                     # å·¥å…·å‡½æ•¸æ¸¬è©¦
â”‚   â”œâ”€â”€ package.json                   # Node.js å°ˆæ¡ˆé…ç½®
â”‚   â”œâ”€â”€ vite.config.ts                 # Vite å»ºç½®é…ç½®
â”‚   â”œâ”€â”€ tsconfig.json                  # TypeScript é…ç½®
â”‚   â”œâ”€â”€ eslint.config.js               # ESLint é…ç½®
â”‚   â”œâ”€â”€ prettier.config.js             # Prettier é…ç½®
â”‚   â””â”€â”€ Dockerfile                     # å‰ç«¯å®¹å™¨é…ç½®
â”œâ”€â”€ .env.example                       # ç’°å¢ƒè®Šæ•¸ç¯„ä¾‹
â”œâ”€â”€ .gitignore                         # Git å¿½ç•¥æª”æ¡ˆ
â”œâ”€â”€ .pre-commit-config.yaml            # pre-commit é…ç½®
â”œâ”€â”€ docker-compose.yml                 # å®¹å™¨ç·¨æ’é…ç½®
â”œâ”€â”€ pyproject.toml                     # æ ¹ç›®éŒ„ Python å·¥å…·é…ç½® (ruff, mypy)
â””â”€â”€ README.md                          # å°ˆæ¡ˆæ–‡ä»¶
```

**Structure Decision**: æ¡ç”¨ Web application çµæ§‹ï¼Œå‰å¾Œç«¯å®Œå…¨åˆ†é›¢ã€‚å¾Œç«¯å°ˆæ³¨ API æœå‹™ï¼Œå‰ç«¯å°ˆæ³¨ä½¿ç”¨è€…ä»‹é¢ã€‚é€é Docker Compose çµ±ä¸€ç®¡ç†æœå‹™ä¾è³´ã€‚æ¯å€‹æ¨¡çµ„æœ‰æ˜ç¢ºè·è²¬åˆ†å·¥ï¼Œä¾¿æ–¼æ¸¬è©¦èˆ‡ç¶­è­·ã€‚

## Phase 0: Research & Setup

### Environment Setup & Dependencies

**Backend Dependencies (pyproject.toml)**:
```toml
[project]
name = "form-analysis-backend"
version = "0.1.0"
requires-python = ">=3.12"
dependencies = [
    "fastapi>=0.104.0",
    "uvicorn[standard]>=0.24.0",
    "pydantic>=2.5.0",
    "sqlalchemy>=2.0.0",
    "alembic>=1.13.0",
    "psycopg[binary]>=3.1.0",
    "python-multipart>=0.0.6",
    "pandas>=2.1.0",
    "openpyxl>=3.1.0",
    "python-json-logger>=2.0.7",
    "uuid-utils>=0.7.0"
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "httpx>=0.25.0",
    "ruff>=0.1.5",
    "black>=23.9.0",
    "mypy>=1.6.0",
    "pre-commit>=3.5.0"
]

[tool.ruff]
line-length = 88
select = ["E", "F", "W", "C901", "I", "N", "UP", "YTT", "ANN", "S", "BLE", "FBT", "B", "A", "COM", "C4", "DTZ", "T10", "ISC", "ICN", "G", "PIE", "T20", "PYI", "PT", "Q", "RSE", "RET", "SLF", "SIM", "TID", "TCH", "INT", "ARG", "PTH", "PL", "R", "TRY", "FLY", "NPY", "RUF"]
ignore = ["ANN101", "ANN102", "COM812", "ISC001"]

[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
warn_unused_configs = true
```

**Frontend Dependencies (package.json)**:
```json
{
  "name": "form-analysis-frontend",
  "version": "0.1.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "lint:fix": "eslint . --ext ts,tsx --fix",
    "format": "prettier --write .",
    "type-check": "tsc --noEmit"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "react-router-dom": "^6.17.0",
    "axios": "^1.5.0"
  },
  "devDependencies": {
    "@types/react": "^18.2.33",
    "@types/react-dom": "^18.2.14",
    "@typescript-eslint/eslint-plugin": "^6.10.0",
    "@typescript-eslint/parser": "^6.10.0",
    "@vitejs/plugin-react": "^4.1.0",
    "eslint": "^8.53.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.4",
    "prettier": "^3.0.3",
    "typescript": "^5.2.2",
    "vite": "^4.5.0",
    "vitest": "^0.34.6",
    "@testing-library/react": "^13.4.0",
    "@testing-library/jest-dom": "^6.1.4"
  }
}
```

**Environment Variables (.env.example)**:
```bash
# Database Configuration
POSTGRES_USER=app
POSTGRES_PASSWORD=app_secure_password
POSTGRES_DB=form_analysis_db
POSTGRES_PORT=5432
DATABASE_URL=postgresql+psycopg://app:app_secure_password@db:5432/form_analysis_db

# API Configuration  
API_PORT=8000
API_HOST=0.0.0.0
MAX_UPLOAD_SIZE_MB=10
UPLOAD_TEMP_DIR=/tmp/uploads
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# Development
DEBUG=false
RELOAD=false
```

### Docker Configuration

**docker-compose.yml**:
```yaml
version: '3.8'

services:
  db:
    image: postgres:16
    container_name: form_analysis_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-app}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-app_secure_password}
      POSTGRES_DB: ${POSTGRES_DB:-form_analysis_db}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-app}"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: form_analysis_api
    depends_on:
      db:
        condition: service_healthy
    environment:
      - DATABASE_URL=postgresql+psycopg://${POSTGRES_USER:-app}:${POSTGRES_PASSWORD:-app_secure_password}@db:5432/${POSTGRES_DB:-form_analysis_db}
      - API_PORT=${API_PORT:-8000}
      - MAX_UPLOAD_SIZE_MB=${MAX_UPLOAD_SIZE_MB:-10}
      - CORS_ORIGINS=${CORS_ORIGINS:-http://localhost:5173}
    ports:
      - "${API_PORT:-8000}:8000"
    volumes:
      - ./backend/uploads:/app/uploads
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: form_analysis_frontend
    depends_on:
      - backend
    ports:
      - "5173:5173"
    environment:
      - VITE_API_URL=http://localhost:8000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5173"]
      interval: 30s
      timeout: 10s
      retries: 3

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: form_analysis_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@example.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    depends_on:
      - db
    profiles:
      - tools

volumes:
  postgres_data:
```

### Database Schema

**Alembic Migration (initial schema)**:
```sql
-- upload_jobs table
CREATE TABLE upload_jobs (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    filename VARCHAR(255) NOT NULL,
    original_filename VARCHAR(255) NOT NULL,
    file_size INTEGER NOT NULL,
    mime_type VARCHAR(100),
    status VARCHAR(50) NOT NULL DEFAULT 'uploaded',
    total_rows INTEGER DEFAULT 0,
    valid_rows INTEGER DEFAULT 0,
    invalid_rows INTEGER DEFAULT 0,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    user_id VARCHAR(100), -- æœªä¾†ä½¿ç”¨è€…èªè­‰ç”¨
    source_ip INET,
    processing_time_ms INTEGER
);

-- upload_errors table  
CREATE TABLE upload_errors (
    id SERIAL PRIMARY KEY,
    job_id UUID NOT NULL REFERENCES upload_jobs(id) ON DELETE CASCADE,
    row_index INTEGER NOT NULL,
    field_name VARCHAR(100),
    error_code VARCHAR(50) NOT NULL,
    error_message TEXT NOT NULL,
    raw_value TEXT,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- records table (business data)
CREATE TABLE records (
    id SERIAL PRIMARY KEY,
    lot_no VARCHAR(20) NOT NULL UNIQUE,
    product_name VARCHAR(255) NOT NULL,
    quantity INTEGER NOT NULL CHECK (quantity >= 0),
    production_date DATE NOT NULL,
    job_id UUID REFERENCES upload_jobs(id),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT CURRENT_TIMESTAMP
);

-- Indexes for performance
CREATE INDEX idx_upload_jobs_status ON upload_jobs(status);
CREATE INDEX idx_upload_jobs_created_at ON upload_jobs(created_at);
CREATE INDEX idx_upload_errors_job_id ON upload_errors(job_id);
CREATE INDEX idx_records_lot_no ON records(lot_no);
CREATE INDEX idx_records_production_date ON records(production_date);
```

## Phase 1: Core Backend Implementation

### API Endpoints Specification

**Core Upload API**:
```python
# POST /api/upload
@router.post("/upload")
async def upload_file(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks
) -> UploadResponse:
    """
    ä¸Šå‚³ä¸¦é©—è­‰æª”æ¡ˆ
    
    Returns:
    {
        "process_id": "uuid-v4",
        "filename": "data.csv", 
        "total_rows": 1000,
        "valid_rows": 980,
        "invalid_rows": 20,
        "status": "validated",
        "sample_errors": [
            {
                "row_index": 5,
                "field": "quantity",
                "error_code": "INVALID_TYPE", 
                "message": "æ•¸é‡å¿…é ˆç‚ºéè² æ•´æ•¸ï¼Œç•¶å‰å€¼ï¼š-5"
            }
        ]
    }
    """

# GET /api/validate
@router.get("/validate")
async def get_validation_result(process_id: UUID) -> ValidationDetailResponse:
    """
    å–å¾—è©³ç´°é©—è­‰çµæœ
    
    Returns:
    {
        "process_id": "uuid-v4",
        "status": "validated|processing|failed",
        "errors": [...], # å®Œæ•´éŒ¯èª¤åˆ—è¡¨
        "preview_data": [...], # å‰10ç­†æœ‰æ•ˆè³‡æ–™
        "summary": {
            "total_rows": 1000,
            "valid_rows": 980, 
            "invalid_rows": 20
        }
    }
    """

# POST /api/import  
@router.post("/import")
async def import_data(request: ImportRequest) -> ImportResponse:
    """
    ç¢ºèªåŒ¯å…¥è³‡æ–™
    
    Body: {"process_id": "uuid-v4"}
    
    Returns:
    {
        "process_id": "uuid-v4",
        "imported_rows": 980,
        "skipped_rows": 20,
        "elapsed_ms": 1250,
        "status": "completed",
        "summary": "æˆåŠŸåŒ¯å…¥ 980 ç­†è³‡æ–™ï¼Œè·³é 20 ç­†éŒ¯èª¤è³‡æ–™"
    }
    """

# GET /api/export/errors/{process_id}
@router.get("/export/errors/{process_id}")
async def export_errors_csv(process_id: UUID) -> StreamingResponse:
    """ä¸‹è¼‰éŒ¯èª¤åˆ—çš„ CSV æª”æ¡ˆ"""

# GET /healthz
@router.get("/healthz")
async def health_check() -> HealthResponse:
    """å¥åº·æª¢æŸ¥ç«¯é»"""
```

### Validation Rules Implementation

**Validation Service**:
```python
# services/validator.py
class DataValidator:
    REQUIRED_FIELDS = ['lot_no', 'product_name', 'quantity', 'production_date']
    LOT_NO_PATTERN = re.compile(r'^\d{7}_\d{2}$')
    
    async def validate_structure(self, df: pd.DataFrame) -> List[ValidationError]:
        """é©—è­‰æ¬„ä½çµæ§‹"""
        errors = []
        
        # æª¢æŸ¥å¿…éœ€æ¬„ä½
        missing_fields = set(self.REQUIRED_FIELDS) - set(df.columns)
        if missing_fields:
            errors.append(ValidationError(
                row_index=0,
                field=None,
                error_code="MISSING_REQUIRED_FIELDS",
                message=f"ç¼ºå°‘å¿…éœ€æ¬„ä½: {', '.join(missing_fields)}"
            ))
            
        # æª¢æŸ¥æœªçŸ¥æ¬„ä½
        unknown_fields = set(df.columns) - set(self.REQUIRED_FIELDS)
        if unknown_fields:
            errors.append(ValidationError(
                row_index=0,
                field=None, 
                error_code="UNKNOWN_FIELDS",
                message=f"æœªçŸ¥æ¬„ä½: {', '.join(unknown_fields)}"
            ))
            
        return errors
    
    async def validate_data(self, df: pd.DataFrame) -> List[ValidationError]:
        """é©—è­‰è³‡æ–™å…§å®¹"""
        errors = []
        
        for idx, row in df.iterrows():
            # lot_no æ ¼å¼é©—è­‰
            if not self.LOT_NO_PATTERN.match(str(row['lot_no'])):
                errors.append(ValidationError(
                    row_index=idx + 1,
                    field='lot_no',
                    error_code='INVALID_FORMAT',
                    message=f'lot_no æ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º 7ä½æ•¸å­—_2ä½æ•¸å­—ï¼Œç•¶å‰å€¼: {row["lot_no"]}'
                ))
            
            # quantity é©—è­‰
            try:
                qty = int(row['quantity'])
                if qty < 0:
                    errors.append(ValidationError(
                        row_index=idx + 1,
                        field='quantity',
                        error_code='INVALID_RANGE', 
                        message=f'æ•¸é‡ä¸èƒ½ç‚ºè² æ•¸ï¼Œç•¶å‰å€¼: {qty}'
                    ))
            except (ValueError, TypeError):
                errors.append(ValidationError(
                    row_index=idx + 1,
                    field='quantity',
                    error_code='INVALID_TYPE',
                    message=f'æ•¸é‡å¿…é ˆç‚ºæ•´æ•¸ï¼Œç•¶å‰å€¼: {row["quantity"]}'
                ))
            
            # production_date é©—è­‰
            try:
                pd.to_datetime(row['production_date'], format='%Y-%m-%d')
            except (ValueError, TypeError):
                errors.append(ValidationError(
                    row_index=idx + 1,
                    field='production_date',
                    error_code='INVALID_DATE_FORMAT',
                    message=f'æ—¥æœŸæ ¼å¼éŒ¯èª¤ï¼Œæ‡‰ç‚º YYYY-MM-DDï¼Œç•¶å‰å€¼: {row["production_date"]}'
                ))
                
        return errors
```

## Phase 2: Frontend Implementation  

### React Components Structure

**Main Upload Flow**:
```typescript
// pages/Upload.tsx
export const Upload: React.FC = () => {
  const [step, setStep] = useState<'upload' | 'validate' | 'import' | 'complete'>('upload');
  const [processId, setProcessId] = useState<string | null>(null);
  const [validationResult, setValidationResult] = useState<ValidationResult | null>(null);

  const handleFileUpload = async (file: File) => {
    const response = await uploadFile(file);
    setProcessId(response.process_id);
    setStep('validate');
  };

  const handleImport = async () => {
    await importData(processId!);
    setStep('complete');
  };

  return (
    <div className="upload-container">
      {step === 'upload' && <FileUploader onUpload={handleFileUpload} />}
      {step === 'validate' && (
        <ValidationResults 
          processId={processId!} 
          onImport={handleImport}
          onBack={() => setStep('upload')}
        />
      )}
      {step === 'import' && <ImportProgress processId={processId!} />}
      {step === 'complete' && <CompletionSummary processId={processId!} />}
    </div>
  );
};

// components/FileUploader.tsx  
export const FileUploader: React.FC<FileUploaderProps> = ({ onUpload }) => {
  const [isDragOver, setIsDragOver] = useState(false);
  const [isUploading, setIsUploading] = useState(false);
  
  const handleDrop = async (event: React.DragEvent) => {
    event.preventDefault();
    const files = Array.from(event.dataTransfer.files);
    const file = files[0];
    
    if (!validateFileType(file)) {
      alert('åƒ…æ”¯æ´ CSV å’Œ Excel (.xlsx) æª”æ¡ˆ');
      return;
    }
    
    if (!validateFileSize(file)) {
      alert('æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é 10MB');
      return;
    }
    
    setIsUploading(true);
    try {
      await onUpload(file);
    } finally {
      setIsUploading(false);
    }
  };
  
  return (
    <div 
      className={`upload-zone ${isDragOver ? 'drag-over' : ''}`}
      onDrop={handleDrop}
      onDragOver={(e) => { e.preventDefault(); setIsDragOver(true); }}
      onDragLeave={() => setIsDragOver(false)}
    >
      {isUploading ? (
        <ProgressBar message="ä¸Šå‚³æª”æ¡ˆä¸­..." />
      ) : (
        <>
          <div className="upload-icon"></div>
          <p>æ‹–æ‹½æª”æ¡ˆåˆ°æ­¤è™•æˆ–é»æ“Šé¸æ“‡æª”æ¡ˆ</p>
          <p className="file-info">æ”¯æ´ CSV, Excel (.xlsx) æª”æ¡ˆï¼Œæœ€å¤§ 10MB</p>
          <input
            type="file"
            accept=".csv,.xlsx"
            onChange={(e) => e.target.files?.[0] && onUpload(e.target.files[0])}
            style={{ display: 'none' }}
            id="file-input"
          />
          <label htmlFor="file-input" className="upload-button">
            é¸æ“‡æª”æ¡ˆ
          </label>
        </>
      )}
    </div>
  );
};
```

## Phase 3: Testing & Quality Assurance

### Testing Strategy

**Backend Tests**:
```python
# tests/test_upload_flow.py
@pytest.mark.asyncio
async def test_complete_upload_flow():
    """æ¸¬è©¦å®Œæ•´ä¸Šå‚³æµç¨‹"""
    # 1. ä¸Šå‚³æª”æ¡ˆ
    with open("fixtures/valid_sample.csv", "rb") as f:
        response = await client.post("/api/upload", files={"file": f})
    
    assert response.status_code == 200
    data = response.json()
    process_id = data["process_id"]
    
    # 2. é©—è­‰çµæœ
    response = await client.get(f"/api/validate?process_id={process_id}")
    assert response.status_code == 200
    
    # 3. åŒ¯å…¥è³‡æ–™  
    response = await client.post("/api/import", json={"process_id": process_id})
    assert response.status_code == 200
    assert data["imported_rows"] > 0

# tests/test_validator.py  
@pytest.mark.asyncio
async def test_lot_no_validation():
    """æ¸¬è©¦ lot_no æ ¼å¼é©—è­‰"""
    validator = DataValidator()
    
    # æœ‰æ•ˆæ ¼å¼
    df_valid = pd.DataFrame({'lot_no': ['1234567_01'], 'product_name': ['test'], 'quantity': [10], 'production_date': ['2025-01-01']})
    errors = await validator.validate_data(df_valid)
    assert len(errors) == 0
    
    # ç„¡æ•ˆæ ¼å¼
    df_invalid = pd.DataFrame({'lot_no': ['123456_1'], 'product_name': ['test'], 'quantity': [10], 'production_date': ['2025-01-01']})
    errors = await validator.validate_data(df_invalid) 
    assert len(errors) == 1
    assert errors[0].error_code == 'INVALID_FORMAT'
```

**Frontend Tests**:
```typescript
// tests/components/FileUploader.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { FileUploader } from '../components/FileUploader';

test('should accept valid CSV file', async () => {
  const mockOnUpload = jest.fn();
  render(<FileUploader onUpload={mockOnUpload} />);
  
  const file = new File(['col1,col2\nval1,val2'], 'test.csv', { type: 'text/csv' });
  const input = screen.getByLabelText(/é¸æ“‡æª”æ¡ˆ/);
  
  fireEvent.change(input, { target: { files: [file] } });
  
  expect(mockOnUpload).toHaveBeenCalledWith(file);
});

test('should reject oversized file', () => {
  const mockOnUpload = jest.fn();
  render(<FileUploader onUpload={mockOnUpload} />);
  
  // Create 15MB file (over 10MB limit)
  const largeContent = 'x'.repeat(15 * 1024 * 1024);
  const file = new File([largeContent], 'large.csv', { type: 'text/csv' });
  const input = screen.getByLabelText(/é¸æ“‡æª”æ¡ˆ/);
  
  fireEvent.change(input, { target: { files: [file] } });
  
  expect(mockOnUpload).not.toHaveBeenCalled();
  expect(screen.getByText(/æª”æ¡ˆå¤§å°ä¸èƒ½è¶…é 10MB/)).toBeInTheDocument();
});
```

### CI/CD Pipeline (.github/workflows/ci.yml)

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_PASSWORD: test_password
          POSTGRES_USER: test_user
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: 3.12
        
    - name: Install dependencies
      run: |
        cd backend
        pip install -e .[dev]
        
    - name: Run linting
      run: |
        cd backend
        ruff check .
        black --check .
        mypy .
        
    - name: Run tests
      run: |
        cd backend  
        pytest --cov=app --cov-report=xml
        
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
        
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: 20
        cache: npm
        cache-dependency-path: frontend/package-lock.json
        
    - name: Install dependencies  
      run: |
        cd frontend
        npm ci
        
    - name: Run linting
      run: |
        cd frontend
        npm run lint
        npm run type-check
        
    - name: Run tests
      run: |
        cd frontend
        npm run test
        
    - name: Build
      run: |
        cd frontend
        npm run build
        
  docker-build:
    needs: [backend-tests, frontend-tests]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Build and test Docker images
      run: |
        docker-compose -f docker-compose.yml build
        docker-compose -f docker-compose.yml up -d
        
        # Health check
        timeout 60 bash -c 'until curl -f http://localhost:8000/healthz; do sleep 2; done'
        timeout 60 bash -c 'until curl -f http://localhost:5173; do sleep 2; done'
        
        docker-compose down
```

## Phase 4: Documentation & Deployment

### README.md Quick Start Guide

```markdown
# è¡¨å–®ä¸Šå‚³é©—è­‰ç³»çµ± MVP

æœ€å°å¯è¡Œçš„æª”æ¡ˆè™•ç†ç³»çµ±ï¼Œæ”¯æ´ CSV/Excel ä¸Šå‚³ã€å³æ™‚é©—è­‰ã€è³‡æ–™é è¦½èˆ‡æ‰¹æ¬¡åŒ¯å…¥ã€‚

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å‰ç½®éœ€æ±‚
- Docker & Docker Compose
- Node.js 20+ (é–‹ç™¼ç’°å¢ƒ)
- Python 3.12+ (é–‹ç™¼ç’°å¢ƒ)

### ä¸€éµå•Ÿå‹• (æ¨è–¦)

```bash
# 1. è¤‡è£½ç’°å¢ƒè®Šæ•¸
cp .env.example .env

# 2. å•Ÿå‹•æ‰€æœ‰æœå‹™ (è³‡æ–™åº« + API + å‰ç«¯)
docker-compose up -d

# 3. åˆå§‹åŒ–è³‡æ–™åº«
docker-compose exec backend alembic upgrade head

# 4. é–‹å•Ÿç€è¦½å™¨
# å‰ç«¯: http://localhost:5173
# API æ–‡ä»¶: http://localhost:8000/docs  
# pgAdmin: http://localhost:5050 (admin@example.com / admin)
```

### é–‹ç™¼ç’°å¢ƒå•Ÿå‹•

```bash
# å¾Œç«¯é–‹ç™¼
cd backend
pip install -e .[dev]
pre-commit install
uvicorn app.main:app --reload --port 8000

# å‰ç«¯é–‹ç™¼  
cd frontend
npm install
npm run dev  # http://localhost:5173

# è³‡æ–™åº« (Docker)
docker-compose up -d db
```

## ğŸ“‹ ä¸»è¦åŠŸèƒ½

### æª”æ¡ˆä¸Šå‚³èˆ‡é©—è­‰
- æ”¯æ´ CSV (UTF-8) å’Œ Excel (.xlsx) æ ¼å¼
- æª”æ¡ˆå¤§å°é™åˆ¶ 10MB
- å³æ™‚æ ¼å¼èˆ‡å…§å®¹é©—è­‰
- å‹å–„çš„ä¸­æ–‡éŒ¯èª¤è¨Šæ¯

### è³‡æ–™é è¦½èˆ‡åŒ¯å…¥
- å¯åŒ¯å…¥è³‡æ–™çš„å³æ™‚é è¦½
- è©³ç´°éŒ¯èª¤åˆ—è¡¨é¡¯ç¤º
- éŒ¯èª¤è³‡æ–™ CSV ä¸‹è¼‰
- äº¤æ˜“æ€§æ‰¹æ¬¡åŒ¯å…¥

### è¿½è¹¤èˆ‡æ—¥èªŒ
- æ¯æ¬¡æ“ä½œç”¢ç”Ÿå”¯ä¸€ process_id
- å®Œæ•´çš„æ“ä½œå¯©è¨ˆæ—¥èªŒ
- è™•ç†æ™‚é–“èˆ‡æ•ˆèƒ½ç›£æ§

##  API è¦æ ¼

### æ ¸å¿ƒç«¯é»

| æ–¹æ³• | è·¯å¾‘ | èªªæ˜ |
|------|------|------|
| POST | `/api/upload` | æª”æ¡ˆä¸Šå‚³èˆ‡é©—è­‰ |
| GET | `/api/validate?process_id=...` | ç²å–è©³ç´°é©—è­‰çµæœ |
| POST | `/api/import` | ç¢ºèªåŒ¯å…¥è³‡æ–™ |
| GET | `/api/export/errors/{process_id}` | ä¸‹è¼‰éŒ¯èª¤ CSV |
| GET | `/healthz` | å¥åº·æª¢æŸ¥ |

### ç¯„ä¾‹è«‹æ±‚

**ä¸Šå‚³æª”æ¡ˆ**:
```bash
curl -X POST "http://localhost:8000/api/upload" \
     -F "file=@sample.csv" \
     -H "Content-Type: multipart/form-data"
```

**åŒ¯å…¥è³‡æ–™**:
```bash
curl -X POST "http://localhost:8000/api/import" \
     -H "Content-Type: application/json" \
     -d '{"process_id": "550e8400-e29b-41d4-a716-446655440000"}'
```

## ğŸ§ª æ¸¬è©¦

### åŸ·è¡Œæ¸¬è©¦

```bash
# å¾Œç«¯æ¸¬è©¦
cd backend
pytest --cov=app

# å‰ç«¯æ¸¬è©¦  
cd frontend
npm run test

# æ•´åˆæ¸¬è©¦
docker-compose -f docker-compose.test.yml up --abort-on-container-exit
```

### æ¸¬è©¦æª”æ¡ˆ

å°ˆæ¡ˆæä¾›æ¸¬è©¦ç”¨çš„ç¯„ä¾‹æª”æ¡ˆï¼š
- `backend/tests/fixtures/valid_sample.csv` - æœ‰æ•ˆè³‡æ–™ç¯„ä¾‹
- `backend/tests/fixtures/invalid_sample.csv` - åŒ…å«éŒ¯èª¤çš„è³‡æ–™
- `backend/tests/fixtures/sample.xlsx` - Excel æ ¼å¼ç¯„ä¾‹

##  é©—è­‰è¦å‰‡

### å¿…éœ€æ¬„ä½
- `lot_no`: æ‰¹è™Ÿ (æ ¼å¼: 7ä½æ•¸å­—_2ä½æ•¸å­—ï¼Œå¦‚ 1234567_01)
- `product_name`: ç”¢å“åç¨± (1-100 å­—å…ƒ)
- `quantity`: æ•¸é‡ (éè² æ•´æ•¸)
- `production_date`: ç”Ÿç”¢æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)

### éŒ¯èª¤åˆ†ç´š
- **é˜»æ“‹æ€§éŒ¯èª¤**: æ¬„ä½çµæ§‹å•é¡Œï¼Œç„¡æ³•é€²è¡ŒåŒ¯å…¥
- **åˆ—ç´šéŒ¯èª¤**: è³‡æ–™æ ¼å¼æˆ–å…§å®¹éŒ¯èª¤ï¼Œè©²åˆ—æœƒè¢«è·³é
- **è­¦å‘Š**: è³‡æ–™å“è³ªå•é¡Œï¼Œä¸å½±éŸ¿åŒ¯å…¥ä½†å»ºè­°æª¢æŸ¥

## ğŸ› ï¸ é–‹ç™¼æŒ‡å—

### ç¨‹å¼ç¢¼å“è³ª
```bash
# Python (å¾Œç«¯)
ruff check . && black . && mypy .

# TypeScript (å‰ç«¯)  
npm run lint && npm run type-check
```

### è³‡æ–™åº« Migration
```bash
# å»ºç«‹æ–°çš„ migration
alembic revision --autogenerate -m "add new table"

# åŸ·è¡Œ migration  
alembic upgrade head

# å›æ»¾ migration
alembic downgrade -1
```

### é™¤éŒ¯æ¨¡å¼
```bash
# é–‹å•Ÿè©³ç´°æ—¥èªŒ
export LOG_LEVEL=DEBUG
export DEBUG=true

# é—œé–‰ CORS (åƒ…é–‹ç™¼ç’°å¢ƒ)
export CORS_ORIGINS=*
```

## â“ å¸¸è¦‹å•é¡Œ

### Windows PowerShell æ¬Šé™å•é¡Œ
```powershell
# è¨­å®šåŸ·è¡Œæ”¿ç­– (ç®¡ç†å“¡æ¬Šé™)
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope LocalMachine

# æˆ–åƒ…é‡å°ç•¶å‰ process
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope Process
```

### ä¸Šå‚³æª”æ¡ˆå¤§å°é™åˆ¶
é è¨­é™åˆ¶ 10MBï¼Œå¯é€éç’°å¢ƒè®Šæ•¸èª¿æ•´ï¼š
```bash
MAX_UPLOAD_SIZE_MB=20  # èª¿æ•´ç‚º 20MB
```

### CORS éŒ¯èª¤
å¦‚æœå‰å¾Œç«¯åœ¨ä¸åŒ port é–‹ç™¼é‡åˆ° CORS å•é¡Œï¼š
```bash
# åœ¨ .env ä¸­è¨­å®š
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:8080
```

### è³‡æ–™åº«é€£ç·šå•é¡Œ
```bash
# æª¢æŸ¥è³‡æ–™åº«æ˜¯å¦å•Ÿå‹•
docker-compose ps

# æŸ¥çœ‹è³‡æ–™åº«æ—¥èªŒ
docker-compose logs db

# é‡å•Ÿè³‡æ–™åº«æœå‹™
docker-compose restart db
```

### æª”æ¡ˆç·¨ç¢¼å•é¡Œ
- ä¸Šå‚³ CSV å»ºè­°ä½¿ç”¨ UTF-8 ç·¨ç¢¼ (æ”¯æ´ BOM)
- Excel æª”æ¡ˆè«‹ç¢ºä¿ç‚º .xlsx æ ¼å¼ (ä¸æ”¯æ´èˆŠç‰ˆ .xls)

### æ•ˆèƒ½å•é¡Œ
- å»ºè­°å–®æ¬¡ä¸Šå‚³æª”æ¡ˆ â‰¤ 50,000 åˆ—
- å¤§æª”æ¡ˆè™•ç†æ™‚é–“è¼ƒé•·ï¼Œè«‹è€å¿ƒç­‰å¾…é©—è­‰å®Œæˆ
- å¯é€é `/healthz` ç«¯é»æª¢æŸ¥ç³»çµ±ç‹€æ…‹

## ğŸ“ˆ ç›£æ§èˆ‡ç¶­é‹

### å¥åº·æª¢æŸ¥
- API: `GET /healthz`
- å‰ç«¯: `GET http://localhost:5173`  
- è³‡æ–™åº«: `docker-compose exec db pg_isready`

### æ—¥èªŒæŸ¥çœ‹
```bash
# API æ—¥èªŒ
docker-compose logs -f backend

# å‰ç«¯æ—¥èªŒ  
docker-compose logs -f frontend

# è³‡æ–™åº«æ—¥èªŒ
docker-compose logs -f db
```

### å‚™ä»½èˆ‡é‚„åŸ
```bash
# å‚™ä»½è³‡æ–™åº«
docker-compose exec db pg_dump -U app form_analysis_db > backup.sql

# é‚„åŸè³‡æ–™åº«
docker-compose exec -T db psql -U app form_analysis_db < backup.sql
```

## ğŸš€ éƒ¨ç½²

### Production ç’°å¢ƒ
```bash
# 1. è¤‡è£½ä¸¦èª¿æ•´ production ç’°å¢ƒè®Šæ•¸
cp .env.example .env.prod

# 2. ä½¿ç”¨ production compose æª”æ¡ˆ
docker-compose -f docker-compose.prod.yml up -d

# 3. åŸ·è¡Œ migrations
docker-compose -f docker-compose.prod.yml exec backend alembic upgrade head
```

### ç’°å¢ƒè®Šæ•¸æª¢æŸ¥æ¸…å–®
- [ ] `POSTGRES_PASSWORD` ä½¿ç”¨å¼·å¯†ç¢¼
- [ ] `DEBUG=false` é—œé–‰é™¤éŒ¯æ¨¡å¼
- [ ] `CORS_ORIGINS` è¨­å®šæ­£ç¢ºçš„å‰ç«¯ç¶²åŸŸ
- [ ] `LOG_LEVEL=INFO` é©ç•¶çš„æ—¥èªŒç´šåˆ¥

## ğŸ“ æ”¯æ´

- ğŸ› Bug å›å ±: [GitHub Issues](https://github.com/your-org/form-analysis-server/issues)
- ğŸ“– API æ–‡ä»¶: http://localhost:8000/docs
- ğŸ“‹ å°ˆæ¡ˆçœ‹æ¿: [GitHub Projects](https://github.com/your-org/form-analysis-server/projects)

---

**ç‰ˆæœ¬**: v1.0.0 | **æ›´æ–°æ—¥æœŸ**: 2025-11-08
```

## åŸ·è¡Œæ¸…å–®èˆ‡å¾…è¾¦ä»»å‹™

### Phase 1: å°ˆæ¡ˆåˆå§‹åŒ– (1-2 å¤©)
- [ ] **T1.1**: å»ºç«‹å°ˆæ¡ˆçµæ§‹èˆ‡ç›®éŒ„
- [ ] **T1.2**: è¨­å®š pyproject.toml èˆ‡ package.json
- [ ] **T1.3**: å»ºç«‹ Docker èˆ‡ docker-compose è¨­å®š
- [ ] **T1.4**: è¨­å®š pre-commit hooks èˆ‡ç¨‹å¼ç¢¼å“è³ªå·¥å…·
- [ ] **T1.5**: å»ºç«‹ .env.example èˆ‡ç’°å¢ƒè®Šæ•¸æ–‡ä»¶
- [ ] **T1.6**: åˆå§‹åŒ– Git repository èˆ‡ .gitignore

### Phase 2: å¾Œç«¯æ ¸å¿ƒå¯¦ä½œ (3-4 å¤©)  
- [ ] **T2.1**: å»ºç«‹ FastAPI æ‡‰ç”¨ç¨‹å¼éª¨æ¶ (main.py, config.py)
- [ ] **T2.2**: è¨­å®š SQLAlchemy èˆ‡è³‡æ–™åº«é€£ç·š
- [ ] **T2.3**: å»ºç«‹ Alembic è¨­å®šèˆ‡åˆå§‹ migration
- [ ] **T2.4**: å¯¦ä½œè³‡æ–™æ¨¡å‹ (upload_jobs, upload_errors, records)
- [ ] **T2.5**: å»ºç«‹ Pydantic schemas èˆ‡ API å›æ‡‰æ ¼å¼
- [ ] **T2.6**: å¯¦ä½œæª”æ¡ˆè§£ææœå‹™ (CSV/Excel)
- [ ] **T2.7**: å¯¦ä½œè³‡æ–™é©—è­‰æœå‹™ (æ ¼å¼èˆ‡å…§å®¹é©—è­‰)
- [ ] **T2.8**: å¯¦ä½œè³‡æ–™åŒ¯å…¥æœå‹™ (äº¤æ˜“æ€§å¯«å…¥)

### Phase 3: API ç«¯é»å¯¦ä½œ (2-3 å¤©)
- [ ] **T3.1**: å¯¦ä½œ `/api/upload` ç«¯é» (æª”æ¡ˆä¸Šå‚³èˆ‡é©—è­‰)
- [ ] **T3.2**: å¯¦ä½œ `/api/validate` ç«¯é» (è©³ç´°é©—è­‰çµæœ)
- [ ] **T3.3**: å¯¦ä½œ `/api/import` ç«¯é» (ç¢ºèªåŒ¯å…¥)
- [ ] **T3.4**: å¯¦ä½œ `/api/export/errors` ç«¯é» (éŒ¯èª¤ CSV ä¸‹è¼‰)
- [ ] **T3.5**: å¯¦ä½œ `/healthz` å¥åº·æª¢æŸ¥ç«¯é»
- [ ] **T3.6**: å»ºç«‹ä¸­ä»‹å±¤ (request_id, è€—æ™‚è¨˜éŒ„, CORS)
- [ ] **T3.7**: è¨­å®š OpenAPI æ–‡ä»¶èˆ‡ Swagger UI

### Phase 4: å‰ç«¯å¯¦ä½œ (3-4 å¤©)
- [ ] **T4.1**: å»ºç«‹ Vite + React + TypeScript å°ˆæ¡ˆéª¨æ¶
- [ ] **T4.2**: å»ºç«‹ API å‘¼å«å°è£ (axios client)
- [ ] **T4.3**: å¯¦ä½œæª”æ¡ˆä¸Šå‚³å…ƒä»¶ (æ‹–æ‹½ + é¸æ“‡æª”æ¡ˆ)
- [ ] **T4.4**: å¯¦ä½œé©—è­‰çµæœé¡¯ç¤º (é è¦½è¡¨æ ¼ + éŒ¯èª¤åˆ—è¡¨)
- [ ] **T4.5**: å¯¦ä½œåŒ¯å…¥ç¢ºèªèˆ‡é€²åº¦é¡¯ç¤º
- [ ] **T4.6**: å¯¦ä½œå®Œæˆçµæœæ‘˜è¦é é¢
- [ ] **T4.7**: å»ºç«‹ TypeScript å‹åˆ¥å®šç¾©
- [ ] **T4.8**: è¨­å®šå‰ç«¯ linting èˆ‡ formatting

### Phase 5: æ¸¬è©¦èˆ‡å“è³ªä¿è­‰ (2-3 å¤©)
- [ ] **T5.1**: å»ºç«‹å¾Œç«¯å–®å…ƒæ¸¬è©¦ (æœå‹™å±¤æ¸¬è©¦)  
- [ ] **T5.2**: å»ºç«‹å¾Œç«¯æ•´åˆæ¸¬è©¦ (API ç«¯é»æ¸¬è©¦)
- [ ] **T5.3**: å»ºç«‹å‰ç«¯å…ƒä»¶æ¸¬è©¦
- [ ] **T5.4**: å»ºç«‹ç«¯åˆ°ç«¯æ¸¬è©¦ (å®Œæ•´ä¸Šå‚³æµç¨‹)
- [ ] **T5.5**: æº–å‚™æ¸¬è©¦æª”æ¡ˆèˆ‡æ¸¬è©¦è³‡æ–™
- [ ] **T5.6**: è¨­å®š CI/CD pipeline (GitHub Actions)
- [ ] **T5.7**: æ•ˆèƒ½æ¸¬è©¦èˆ‡å¤§æª”æ¡ˆè™•ç†æ¸¬è©¦

### Phase 6: éƒ¨ç½²èˆ‡æ–‡ä»¶ (1-2 å¤©)
- [ ] **T6.1**: å®Œå–„ README.md æ–‡ä»¶
- [ ] **T6.2**: å»ºç«‹ production Docker è¨­å®š
- [ ] **T6.3**: è¨­å®šå¥åº·æª¢æŸ¥èˆ‡ç›£æ§
- [ ] **T6.4**: å»ºç«‹éƒ¨ç½²æŒ‡å—èˆ‡ç¶­é‹æ‰‹å†Š
- [ ] **T6.5**: ä½¿ç”¨è€…é©—æ”¶æ¸¬è©¦
- [ ] **T6.6**: æ•ˆèƒ½èª¿å„ªèˆ‡æœ€çµ‚æ¸¬è©¦

### ç¸½é ä¼°æ™‚ç¨‹: 12-18 å¤© (2-3 é€±)

æ¯å€‹ä»»å‹™éƒ½æœ‰æ˜ç¢ºçš„äº¤ä»˜æˆæœï¼Œå¯ç¨ç«‹é©—æ”¶ï¼Œä¾¿æ–¼è¿½è¹¤é€²åº¦èˆ‡å“è³ªæ§åˆ¶ã€‚
