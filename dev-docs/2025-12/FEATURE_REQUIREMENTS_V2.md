# æ–°åŠŸèƒ½éœ€æ±‚åˆ†æèˆ‡å¯¦ä½œå»ºè­° (ç¬¬äºŒç‰ˆ)

**æ–‡æª”æ—¥æœŸ**: 2025å¹´12æœˆ10æ—¥  
**ç‰ˆæœ¬**: 2.0

---

## æ–°éœ€æ±‚æ¦‚è¿°

1. **PDF ä¸Šå‚³å°æ¥å¤–éƒ¨ Server**
2. **P3 æ¬„ä½æœå°‹æ’åºåŠŸèƒ½**
3. **Product_ID çµ„åˆé‚è¼¯è¨­è¨ˆ**

---

## 1ï¸âƒ£ PDF ä¸Šå‚³å°æ¥å¤–éƒ¨ Server

### å ´æ™¯åˆ†æ

#### å°æ¥æ–¹å¼é¸æ“‡

æ ¹æ“šä¸åŒçš„å°æ¥éœ€æ±‚ï¼Œæœ‰ä»¥ä¸‹å¹¾ç¨®æ¶æ§‹æ–¹æ¡ˆï¼š

###  æ¶æ§‹æ–¹æ¡ˆ

#### æ–¹æ¡ˆ Aï¼šç›´æ¥è½‰ç™¼æ¨¡å¼ï¼ˆæ¨è–¦ï¼‰

**é©ç”¨å ´æ™¯**: 
- å¤–éƒ¨ Server è² è²¬ PDF è™•ç†ï¼ˆOCRã€è¡¨æ ¼æå–ç­‰ï¼‰
- æœ¬ç³»çµ±åƒ…è² è²¬æ¥æ”¶å’Œé©—è­‰

**æµç¨‹**:
```
ä½¿ç”¨è€…ä¸Šå‚³ PDF
    â†“
æœ¬ç³»çµ± Frontend
    â†“
æœ¬ç³»çµ± Backend (æ¥æ”¶ã€é©—è­‰æª”æ¡ˆ)
    â†“
å¤–éƒ¨ PDF Server (è™•ç† PDF â†’ è¿”å›çµæ§‹åŒ–è³‡æ–™)
    â†“
æœ¬ç³»çµ± Backend (æ¥æ”¶çµæ§‹åŒ–è³‡æ–™ â†’ é©—è­‰ â†’ åŒ¯å…¥è³‡æ–™åº«)
    â†“
è¿”å›çµæœçµ¦ä½¿ç”¨è€…
```

**å¯¦ä½œæ­¥é©Ÿ**:

##### æ­¥é©Ÿ 1: å»ºç«‹ PDF Server å®¢æˆ¶ç«¯æœå‹™

```python
# services/pdf_server_client.py

import httpx
import asyncio
from typing import Dict, Any, Optional, BinaryIO
from app.core.config import get_settings
from app.core.logging import get_logger

logger = get_logger(__name__)
settings = get_settings()


class PDFServerClient:
    """PDF è™•ç†ä¼ºæœå™¨å®¢æˆ¶ç«¯"""
    
    def __init__(self):
        self.base_url = settings.pdf_server_url  # å¤–éƒ¨ Server URL
        self.api_key = settings.pdf_server_api_key  # API é‡‘é‘°
        self.timeout = 300.0  # 5åˆ†é˜ timeoutï¼ˆPDF è™•ç†è¼ƒæ…¢ï¼‰
    
    async def upload_and_process_pdf(
        self, 
        file_content: bytes,
        filename: str,
        options: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        ä¸Šå‚³ PDF åˆ°å¤–éƒ¨ Server ä¸¦è™•ç†
        
        Args:
            file_content: PDF æª”æ¡ˆå…§å®¹
            filename: æª”æ¡ˆåç¨±
            options: è™•ç†é¸é …ï¼ˆå¦‚é ç¢¼ç¯„åœã€æå–æ¨¡å¼ç­‰ï¼‰
            
        Returns:
            Dict: è™•ç†çµæœï¼ŒåŒ…å«æå–çš„è¡¨æ ¼è³‡æ–™
            
        Raises:
            PDFServerError: Server è™•ç†å¤±æ•—
        """
        try:
            logger.info("ä¸Šå‚³ PDF åˆ°å¤–éƒ¨ Server", filename=filename)
            
            # æº–å‚™è«‹æ±‚
            files = {
                'file': (filename, file_content, 'application/pdf')
            }
            
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'X-Request-Source': 'form-analysis-system'
            }
            
            data = options or {}
            
            # ç™¼é€è«‹æ±‚
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.base_url}/api/pdf/extract",
                    files=files,
                    data=data,
                    headers=headers
                )
                
                # æª¢æŸ¥å›æ‡‰
                if response.status_code != 200:
                    error_detail = response.json().get('detail', 'Unknown error')
                    raise PDFServerError(
                        f"PDF Server è™•ç†å¤±æ•—: {error_detail}",
                        status_code=response.status_code
                    )
                
                result = response.json()
                logger.info("PDF è™•ç†æˆåŠŸ", 
                           filename=filename,
                           rows_extracted=result.get('total_rows', 0))
                
                return result
                
        except httpx.TimeoutException:
            logger.error("PDF Server è«‹æ±‚è¶…æ™‚", filename=filename)
            raise PDFServerError("PDF è™•ç†è¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦")
        
        except httpx.RequestError as e:
            logger.error("PDF Server é€£æ¥å¤±æ•—", filename=filename, error=str(e))
            raise PDFServerError(f"ç„¡æ³•é€£æ¥åˆ° PDF è™•ç†ä¼ºæœå™¨: {str(e)}")
    
    async def check_server_health(self) -> bool:
        """æª¢æŸ¥å¤–éƒ¨ Server å¥åº·ç‹€æ…‹"""
        try:
            async with httpx.AsyncClient(timeout=5.0) as client:
                response = await client.get(f"{self.base_url}/health")
                return response.status_code == 200
        except:
            return False
    
    async def get_processing_status(self, job_id: str) -> Dict[str, Any]:
        """
        æŸ¥è©¢ PDF è™•ç†ç‹€æ…‹ï¼ˆå¦‚æœæ˜¯éåŒæ­¥è™•ç†ï¼‰
        
        Args:
            job_id: è™•ç†ä»»å‹™ ID
            
        Returns:
            Dict: ä»»å‹™ç‹€æ…‹è³‡è¨Š
        """
        try:
            headers = {'Authorization': f'Bearer {self.api_key}'}
            
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.base_url}/api/pdf/status/{job_id}",
                    headers=headers
                )
                
                if response.status_code != 200:
                    raise PDFServerError("ç„¡æ³•æŸ¥è©¢è™•ç†ç‹€æ…‹")
                
                return response.json()
                
        except Exception as e:
            logger.error("æŸ¥è©¢ PDF è™•ç†ç‹€æ…‹å¤±æ•—", job_id=job_id, error=str(e))
            raise


class PDFServerError(Exception):
    """PDF Server éŒ¯èª¤"""
    def __init__(self, message: str, status_code: Optional[int] = None):
        self.message = message
        self.status_code = status_code
        super().__init__(self.message)


# å»ºç«‹å–®ä¾‹
pdf_server_client = PDFServerClient()
```

##### æ­¥é©Ÿ 2: æ›´æ–°é…ç½®æª”æ¡ˆ

```python
# core/config.py

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    # ... ç¾æœ‰è¨­å®š ...
    
    # PDF Server è¨­å®š
    pdf_server_url: str = "http://pdf-server.example.com"
    pdf_server_api_key: str = "your-api-key-here"
    pdf_processing_timeout: int = 300  # 5åˆ†é˜
    pdf_async_mode: bool = False  # æ˜¯å¦ä½¿ç”¨éåŒæ­¥è™•ç†
    
    class Config:
        env_file = ".env"
```

```env
# .env.example

# PDF Server è¨­å®š
PDF_SERVER_URL=http://pdf-server.example.com
PDF_SERVER_API_KEY=your-api-key-here
PDF_PROCESSING_TIMEOUT=300
PDF_ASYNC_MODE=false
```

##### æ­¥é©Ÿ 3: æ•´åˆåˆ°ä¸Šå‚³è·¯ç”±

```python
# api/routes_upload.py

from app.services.pdf_server_client import pdf_server_client, PDFServerError

async def upload_file(
    file: UploadFile = File(...),
    db: AsyncSession = Depends(get_db)
) -> FileUploadResponse:
    """è™•ç†æª”æ¡ˆä¸Šå‚³"""
    
    # åˆ¤æ–·æª”æ¡ˆé¡å‹
    file_type = file_validation_service._get_file_type(file.filename)
    
    if file_type == 'pdf':
        logger.info("è™•ç† PDF æª”æ¡ˆï¼ˆä½¿ç”¨å¤–éƒ¨ Serverï¼‰", filename=file.filename)
        
        try:
            # è®€å–æª”æ¡ˆå…§å®¹
            file_content = await file.read()
            
            # æª¢æŸ¥æª”æ¡ˆå¤§å°ï¼ˆPDF å¯èƒ½è¼ƒå¤§ï¼‰
            max_size = 20 * 1024 * 1024  # 20MB
            if len(file_content) > max_size:
                raise HTTPException(
                    status_code=413,
                    detail=f"PDF æª”æ¡ˆéå¤§ï¼Œæœ€å¤§æ”¯æ´ {max_size // 1024 // 1024}MB"
                )
            
            # ä¸Šå‚³åˆ°å¤–éƒ¨ Server è™•ç†
            processing_options = {
                'extract_mode': 'table',  # è¡¨æ ¼æ¨¡å¼
                'output_format': 'json',  # JSON æ ¼å¼
                'detect_headers': True    # è‡ªå‹•åµæ¸¬æ¨™é¡Œ
            }
            
            result = await pdf_server_client.upload_and_process_pdf(
                file_content=file_content,
                filename=file.filename,
                options=processing_options
            )
            
            # å°‡å¤–éƒ¨ Server è¿”å›çš„è³‡æ–™è½‰æ›ç‚º DataFrame
            df = pd.DataFrame(result.get('data', []))
            
            if df.empty:
                raise HTTPException(
                    status_code=422,
                    detail="PDF ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¡¨æ ¼è³‡æ–™"
                )
            
            # ç¹¼çºŒä½¿ç”¨ç¾æœ‰çš„é©—è­‰æµç¨‹
            validation_result = await file_validation_service.validate_data(
                df=df,
                filename=file.filename
            )
            
            # è¨˜éŒ„é¡å¤–è³‡è¨Š
            logger.info("PDF è™•ç†å®Œæˆ",
                       filename=file.filename,
                       pages_processed=result.get('pages_processed'),
                       tables_found=result.get('tables_found'))
            
        except PDFServerError as e:
            logger.error("PDF Server è™•ç†å¤±æ•—", 
                        filename=file.filename,
                        error=str(e))
            raise HTTPException(
                status_code=502,
                detail=f"PDF è™•ç†å¤±æ•—: {e.message}"
            )
        
        except Exception as e:
            logger.error("PDF è™•ç†ç•°å¸¸", 
                        filename=file.filename,
                        error=str(e))
            raise HTTPException(
                status_code=500,
                detail=f"PDF è™•ç†æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            )
    
    else:
        # CSV/Excel ä½¿ç”¨ç¾æœ‰é‚è¼¯
        validation_result = await file_validation_service.validate_file(file=file)
    
    # ... å‰©é¤˜è™•ç†é‚è¼¯ ...
```

##### æ­¥é©Ÿ 4: æ–°å¢å¥åº·æª¢æŸ¥ç«¯é»

```python
# api/routes_health.py

from app.services.pdf_server_client import pdf_server_client

@router.get("/health/dependencies")
async def check_dependencies_health():
    """æª¢æŸ¥å¤–éƒ¨ä¾è³´æœå‹™å¥åº·ç‹€æ…‹"""
    
    pdf_server_status = await pdf_server_client.check_server_health()
    
    return {
        "status": "healthy" if pdf_server_status else "degraded",
        "dependencies": {
            "pdf_server": {
                "status": "up" if pdf_server_status else "down",
                "url": settings.pdf_server_url
            },
            "database": {
                "status": "up",  # å¾ç¾æœ‰æª¢æŸ¥å–å¾—
            }
        }
    }
```

---

#### æ–¹æ¡ˆ Bï¼šéåŒæ­¥è™•ç†æ¨¡å¼

**é©ç”¨å ´æ™¯**: PDF è™•ç†æ™‚é–“å¾ˆé•·ï¼ˆ>1åˆ†é˜ï¼‰

**æµç¨‹**:
```
ä½¿ç”¨è€…ä¸Šå‚³ PDF
    â†“
æœ¬ç³»çµ±æ¥æ”¶ â†’ è¿”å› job_id
    â†“
èƒŒæ™¯ä»»å‹™: ç™¼é€åˆ°å¤–éƒ¨ Server
    â†“
è¼ªè©¢æˆ– Webhook å–å¾—çµæœ
    â†“
è™•ç†å®Œæˆå¾Œé€šçŸ¥ä½¿ç”¨è€…
```

**æ ¸å¿ƒç¨‹å¼ç¢¼**:

```python
# api/routes_upload.py

@router.post("/upload/async")
async def upload_file_async(
    file: UploadFile = File(...),
    background_tasks: BackgroundTasks,
    db: AsyncSession = Depends(get_db)
):
    """éåŒæ­¥æª”æ¡ˆä¸Šå‚³ï¼ˆé©ç”¨æ–¼å¤§å‹ PDFï¼‰"""
    
    if file.filename.lower().endswith('.pdf'):
        # å»ºç«‹ä¸Šå‚³ä»»å‹™
        upload_job = UploadJob(
            filename=file.filename,
            status=JobStatus.PROCESSING
        )
        db.add(upload_job)
        await db.commit()
        
        # å„²å­˜æª”æ¡ˆåˆ°è‡¨æ™‚ä½ç½®
        temp_path = f"/tmp/{upload_job.process_id}_{file.filename}"
        with open(temp_path, "wb") as f:
            f.write(await file.read())
        
        # èƒŒæ™¯ä»»å‹™è™•ç†
        background_tasks.add_task(
            process_pdf_async,
            upload_job.process_id,
            temp_path,
            db
        )
        
        return {
            "process_id": str(upload_job.process_id),
            "status": "processing",
            "message": "PDF æ­£åœ¨è™•ç†ä¸­ï¼Œè«‹ç¨å¾ŒæŸ¥è©¢çµæœ"
        }


async def process_pdf_async(process_id: uuid.UUID, file_path: str, db: AsyncSession):
    """èƒŒæ™¯è™•ç† PDF"""
    try:
        # ä¸Šå‚³åˆ°å¤–éƒ¨ Server
        with open(file_path, 'rb') as f:
            result = await pdf_server_client.upload_and_process_pdf(
                file_content=f.read(),
                filename=os.path.basename(file_path)
            )
        
        # è™•ç†çµæœ
        df = pd.DataFrame(result['data'])
        validation_result = await file_validation_service.validate_data(df, filename)
        
        # æ›´æ–°ä»»å‹™ç‹€æ…‹
        upload_job = await db.get(UploadJob, process_id)
        upload_job.status = JobStatus.COMPLETED
        await db.commit()
        
    except Exception as e:
        logger.error(f"èƒŒæ™¯è™•ç† PDF å¤±æ•—: {str(e)}")
        upload_job.status = JobStatus.FAILED
        await db.commit()
    finally:
        # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
        os.unlink(file_path)


@router.get("/upload/status/{process_id}")
async def get_upload_status(
    process_id: uuid.UUID,
    db: AsyncSession = Depends(get_db)
):
    """æŸ¥è©¢ä¸Šå‚³è™•ç†ç‹€æ…‹"""
    upload_job = await db.get(UploadJob, process_id)
    if not upload_job:
        raise HTTPException(404, "æ‰¾ä¸åˆ°è™•ç†ä»»å‹™")
    
    return {
        "process_id": str(process_id),
        "status": upload_job.status,
        "progress": upload_job.progress,
        "total_rows": upload_job.total_rows,
        "error_message": upload_job.error_message
    }
```

---

#### æ–¹æ¡ˆ Cï¼šWebhook å›èª¿æ¨¡å¼

**é©ç”¨å ´æ™¯**: å¤–éƒ¨ Server ä¸»å‹•æ¨é€çµæœ

**æµç¨‹**:
```python
# api/routes_webhook.py

@router.post("/webhook/pdf-processed")
async def pdf_processing_webhook(
    webhook_data: Dict[str, Any],
    db: AsyncSession = Depends(get_db)
):
    """æ¥æ”¶ PDF è™•ç†å®Œæˆçš„ Webhook"""
    
    # é©—è­‰ä¾†æºï¼ˆæª¢æŸ¥ç°½åï¼‰
    if not verify_webhook_signature(webhook_data):
        raise HTTPException(403, "ç„¡æ•ˆçš„ Webhook ç°½å")
    
    process_id = webhook_data.get('process_id')
    status = webhook_data.get('status')
    data = webhook_data.get('data')
    
    # æ›´æ–°ä»»å‹™
    upload_job = await db.get(UploadJob, uuid.UUID(process_id))
    if not upload_job:
        raise HTTPException(404, "æ‰¾ä¸åˆ°è™•ç†ä»»å‹™")
    
    if status == 'success':
        # è™•ç†æˆåŠŸï¼ŒåŒ¯å…¥è³‡æ–™
        df = pd.DataFrame(data)
        await import_service.import_records(df, upload_job.data_type, db)
        upload_job.status = JobStatus.COMPLETED
    else:
        # è™•ç†å¤±æ•—
        upload_job.status = JobStatus.FAILED
        upload_job.error_message = webhook_data.get('error')
    
    await db.commit()
    
    return {"status": "received"}


def verify_webhook_signature(data: Dict[str, Any]) -> bool:
    """é©—è­‰ Webhook ç°½å"""
    signature = data.get('signature')
    # å¯¦ä½œç°½åé©—è­‰é‚è¼¯
    # ä¾‹å¦‚: HMAC-SHA256
    return True  # ç°¡åŒ–ç¤ºç¯„
```

---

### å°æ¥è¦ç¯„å»ºè­°

#### API å¥‘ç´„ç¯„ä¾‹

```json
// è«‹æ±‚æ ¼å¼
POST /api/pdf/extract
Headers:
  - Authorization: Bearer {api_key}
  - Content-Type: multipart/form-data

Body:
  - file: {PDF æª”æ¡ˆ}
  - extract_mode: "table" | "text" | "mixed"
  - output_format: "json" | "csv"
  - detect_headers: true | false

// å›æ‡‰æ ¼å¼ï¼ˆæˆåŠŸï¼‰
{
  "status": "success",
  "process_id": "uuid",
  "pages_processed": 5,
  "tables_found": 3,
  "data": [
    {
      "lot_no": "2503033_01",
      "product_name": "ç”¢å“A",
      "quantity": 100,
      "...": "..."
    }
  ],
  "metadata": {
    "processing_time": 12.5,
    "confidence_score": 0.95
  }
}

// å›æ‡‰æ ¼å¼ï¼ˆå¤±æ•—ï¼‰
{
  "status": "error",
  "error_code": "INVALID_PDF_FORMAT",
  "message": "PDF æ ¼å¼ç„¡æ•ˆæˆ–æå£",
  "details": "..."
}
```

#### éŒ¯èª¤è™•ç†ç­–ç•¥

```python
# é‡è©¦æ©Ÿåˆ¶
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
async def upload_pdf_with_retry(file_content: bytes, filename: str):
    """å¸¶é‡è©¦çš„ PDF ä¸Šå‚³"""
    return await pdf_server_client.upload_and_process_pdf(
        file_content, filename
    )
```

---

## 2ï¸âƒ£ P3 æ¬„ä½æœå°‹æ’åºåŠŸèƒ½

### çµè«–ï¼šå®Œå…¨å¯ä»¥å¯¦ä½œï¼

### å¯¦ä½œæ–¹æ¡ˆ

#### æ–¹æ¡ˆ Aï¼šå¤šæ¬„ä½å‹•æ…‹æ’åºï¼ˆæ¨è–¦ï¼‰

```python
# api/routes_query.py

from enum import Enum
from typing import List

class SortField(str, Enum):
    """å¯æ’åºçš„æ¬„ä½"""
    LOT_NO = "lot_no"
    P3_NO = "p3_no"
    PRODUCT_NAME = "product_name"
    QUANTITY = "quantity"
    PRODUCTION_DATE = "production_date"
    CREATED_AT = "created_at"


class SortOrder(str, Enum):
    """æ’åºæ–¹å‘"""
    ASC = "asc"   # å‡åº
    DESC = "desc"  # é™åº


@router.get(
    "/p3/search",
    response_model=QueryResponse,
    summary="P3 è³‡æ–™æœå°‹ï¼ˆæ”¯æ´æ’åºï¼‰",
    description="æ”¯æ´å¤šæ¬„ä½æœå°‹å’Œéˆæ´»æ’åº"
)
async def search_p3_records(
    # æœå°‹æ¢ä»¶
    p3_no: Optional[str] = Query(None, description="P3è¿½è¹¤ç·¨è™Ÿ"),
    product_name: Optional[str] = Query(None, description="ç”¢å“åç¨±"),
    lot_no: Optional[str] = Query(None, description="æ‰¹è™Ÿ"),
    quantity_min: Optional[int] = Query(None, description="æ•¸é‡æœ€å°å€¼"),
    quantity_max: Optional[int] = Query(None, description="æ•¸é‡æœ€å¤§å€¼"),
    production_date_start: Optional[date] = Query(None, description="ç”Ÿç”¢æ—¥æœŸèµ·å§‹"),
    production_date_end: Optional[date] = Query(None, description="ç”Ÿç”¢æ—¥æœŸçµæŸ"),
    
    # æ’åºåƒæ•¸
    sort_by: Optional[List[SortField]] = Query(
        default=[SortField.CREATED_AT],
        description="æ’åºæ¬„ä½ï¼ˆå¯å¤šå€‹ï¼‰ï¼Œä¾‹å¦‚: ?sort_by=production_date&sort_by=lot_no"
    ),
    sort_order: Optional[List[SortOrder]] = Query(
        default=[SortOrder.DESC],
        description="æ’åºæ–¹å‘ï¼ˆå°æ‡‰ sort_byï¼‰ï¼Œä¾‹å¦‚: ?sort_order=desc&sort_order=asc"
    ),
    
    # åˆ†é 
    page: int = Query(1, ge=1, description="é ç¢¼"),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é è¨˜éŒ„æ•¸"),
    
    db: AsyncSession = Depends(get_db)
) -> QueryResponse:
    """P3 è³‡æ–™é€²éšæœå°‹ï¼ˆæ”¯æ´å¤šæ¬„ä½æ’åºï¼‰"""
    
    try:
        logger.info("P3 æœå°‹é–‹å§‹", 
                   p3_no=p3_no, 
                   product_name=product_name,
                   sort_by=sort_by,
                   sort_order=sort_order)
        
        # å»ºæ§‹æŸ¥è©¢æ¢ä»¶
        conditions = [Record.data_type == DataType.P3]
        
        # P3 ç·¨è™Ÿæ¨¡ç³Šæœå°‹
        if p3_no:
            conditions.append(Record.p3_no.ilike(f"%{p3_no}%"))
        
        # ç”¢å“åç¨±æ¨¡ç³Šæœå°‹
        if product_name:
            conditions.append(Record.product_name.ilike(f"%{product_name}%"))
        
        # æ‰¹è™Ÿæ¨¡ç³Šæœå°‹
        if lot_no:
            conditions.append(Record.lot_no.ilike(f"%{lot_no}%"))
        
        # æ•¸é‡ç¯„åœ
        if quantity_min is not None:
            conditions.append(Record.quantity >= quantity_min)
        if quantity_max is not None:
            conditions.append(Record.quantity <= quantity_max)
        
        # æ—¥æœŸç¯„åœ
        if production_date_start:
            conditions.append(Record.production_date >= production_date_start)
        if production_date_end:
            conditions.append(Record.production_date <= production_date_end)
        
        # å»ºæ§‹æŸ¥è©¢
        query_stmt = select(Record).where(and_(*conditions))
        
        # å‹•æ…‹æ’åº
        order_clauses = []
        for i, field in enumerate(sort_by):
            # å–å¾—å°æ‡‰çš„æ’åºæ–¹å‘
            order = sort_order[i] if i < len(sort_order) else SortOrder.ASC
            
            # æ ¹æ“šæ¬„ä½å»ºæ§‹æ’åºå­å¥
            if field == SortField.LOT_NO:
                order_clause = Record.lot_no
            elif field == SortField.P3_NO:
                order_clause = Record.p3_no
            elif field == SortField.PRODUCT_NAME:
                order_clause = Record.product_name
            elif field == SortField.QUANTITY:
                order_clause = Record.quantity
            elif field == SortField.PRODUCTION_DATE:
                order_clause = Record.production_date
            elif field == SortField.CREATED_AT:
                order_clause = Record.created_at
            else:
                continue
            
            # å¥—ç”¨æ’åºæ–¹å‘
            if order == SortOrder.DESC:
                order_clause = order_clause.desc()
            else:
                order_clause = order_clause.asc()
            
            # è™•ç† NULL å€¼ï¼ˆæ”¾åœ¨æœ€å¾Œï¼‰
            if field in [SortField.PRODUCTION_DATE, SortField.P3_NO, 
                        SortField.PRODUCT_NAME, SortField.QUANTITY]:
                order_clause = order_clause.nullslast()
            
            order_clauses.append(order_clause)
        
        # è¨ˆç®—ç¸½æ•¸
        count_query = select(func.count(Record.id)).where(and_(*conditions))
        count_result = await db.execute(count_query)
        total_count = count_result.scalar() or 0
        
        # å¥—ç”¨æ’åºå’Œåˆ†é 
        offset = (page - 1) * page_size
        query_stmt = query_stmt.order_by(*order_clauses).offset(offset).limit(page_size)
        
        # åŸ·è¡ŒæŸ¥è©¢
        result = await db.execute(query_stmt)
        records = result.scalars().all()
        
        # è½‰æ›ç‚ºå›æ‡‰æ ¼å¼
        query_records = []
        for record in records:
            query_record = QueryRecord(
                id=str(record.id),
                lot_no=record.lot_no,
                data_type=record.data_type.value,
                production_date=record.production_date.isoformat() if record.production_date else None,
                created_at=record.created_at.isoformat(),
                display_name=record.display_name,
                p3_no=record.p3_no,
                product_name=record.product_name,
                quantity=record.quantity,
                notes=record.notes,
                additional_data=record.additional_data
            )
            query_records.append(query_record)
        
        logger.info("P3 æœå°‹å®Œæˆ", 
                   total_count=total_count,
                   returned_count=len(query_records),
                   sort_by=sort_by)
        
        return QueryResponse(
            total_count=total_count,
            page=page,
            page_size=page_size,
            records=query_records,
            sort_info={  # é¡å¤–è¿”å›æ’åºè³‡è¨Š
                "sort_by": [s.value for s in sort_by],
                "sort_order": [o.value for o in sort_order]
            }
        )
        
    except Exception as e:
        logger.error("P3 æœå°‹å¤±æ•—", error=str(e))
        raise HTTPException(
            status_code=500,
            detail=f"æœå°‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
        )
```

#### å‰ç«¯ä½¿ç”¨ç¯„ä¾‹

```typescript
// frontend/src/api/queries.ts

interface P3SearchParams {
  p3_no?: string;
  product_name?: string;
  lot_no?: string;
  quantity_min?: number;
  quantity_max?: number;
  production_date_start?: string;
  production_date_end?: string;
  sort_by?: string[];  // ['production_date', 'lot_no']
  sort_order?: string[]; // ['desc', 'asc']
  page?: number;
  page_size?: number;
}

export const searchP3Records = async (params: P3SearchParams) => {
  const queryParams = new URLSearchParams();
  
  // åŸºæœ¬æœå°‹åƒæ•¸
  if (params.p3_no) queryParams.append('p3_no', params.p3_no);
  if (params.product_name) queryParams.append('product_name', params.product_name);
  // ... å…¶ä»–åƒæ•¸
  
  // æ’åºåƒæ•¸ï¼ˆå¯å¤šå€‹ï¼‰
  params.sort_by?.forEach(field => queryParams.append('sort_by', field));
  params.sort_order?.forEach(order => queryParams.append('sort_order', order));
  
  // åˆ†é 
  queryParams.append('page', String(params.page || 1));
  queryParams.append('page_size', String(params.page_size || 20));
  
  const response = await fetch(
    `${API_BASE_URL}/api/p3/search?${queryParams.toString()}`
  );
  
  return response.json();
};

// ä½¿ç”¨ç¯„ä¾‹
const results = await searchP3Records({
  product_name: 'ç”¢å“A',
  sort_by: ['production_date', 'lot_no'],
  sort_order: ['desc', 'asc'],  // æ—¥æœŸé™åºï¼Œæ‰¹è™Ÿå‡åº
  page: 1,
  page_size: 20
});
```

#### UI çµ„ä»¶ç¯„ä¾‹

```typescript
// frontend/src/components/P3SearchWithSort.tsx

import React, { useState } from 'react';
import { ArrowUpIcon, ArrowDownIcon } from '@heroicons/react/24/outline';

interface SortConfig {
  field: string;
  order: 'asc' | 'desc';
}

function P3SearchWithSort() {
  const [sortConfig, setSortConfig] = useState<SortConfig[]>([
    { field: 'production_date', order: 'desc' }
  ]);
  
  const handleSort = (field: string) => {
    setSortConfig(prev => {
      const existing = prev.find(s => s.field === field);
      
      if (existing) {
        // åˆ‡æ›æ’åºæ–¹å‘
        return prev.map(s => 
          s.field === field 
            ? { ...s, order: s.order === 'asc' ? 'desc' : 'asc' }
            : s
        );
      } else {
        // æ–°å¢æ’åºæ¬„ä½
        return [...prev, { field, order: 'asc' }];
      }
    });
  };
  
  const getSortIcon = (field: string) => {
    const config = sortConfig.find(s => s.field === field);
    if (!config) return null;
    
    return config.order === 'asc' 
      ? <ArrowUpIcon className="w-4 h-4" />
      : <ArrowDownIcon className="w-4 h-4" />;
  };
  
  return (
    <div>
      {/* æœå°‹è¡¨å–® */}
      <div className="mb-4">
        <input 
          type="text" 
          placeholder="P3 ç·¨è™Ÿ"
          className="border p-2 rounded"
        />
        {/* å…¶ä»–æœå°‹æ¬„ä½ */}
      </div>
      
      {/* æ’åºé¸é … */}
      <div className="mb-4">
        <label className="font-bold">æ’åº:</label>
        <div className="flex gap-2 mt-2">
          {['production_date', 'lot_no', 'p3_no', 'quantity'].map(field => (
            <button
              key={field}
              onClick={() => handleSort(field)}
              className={`px-3 py-1 rounded border flex items-center gap-1 ${
                sortConfig.some(s => s.field === field) 
                  ? 'bg-blue-500 text-white' 
                  : 'bg-gray-100'
              }`}
            >
              {field === 'production_date' && 'ç”Ÿç”¢æ—¥æœŸ'}
              {field === 'lot_no' && 'æ‰¹è™Ÿ'}
              {field === 'p3_no' && 'P3ç·¨è™Ÿ'}
              {field === 'quantity' && 'æ•¸é‡'}
              {getSortIcon(field)}
            </button>
          ))}
        </div>
      </div>
      
      {/* çµæœè¡¨æ ¼ */}
      <table className="w-full border-collapse">
        <thead>
          <tr className="bg-gray-100">
            <th 
              className="border p-2 cursor-pointer hover:bg-gray-200"
              onClick={() => handleSort('lot_no')}
            >
              æ‰¹è™Ÿ {getSortIcon('lot_no')}
            </th>
            <th 
              className="border p-2 cursor-pointer hover:bg-gray-200"
              onClick={() => handleSort('production_date')}
            >
              ç”Ÿç”¢æ—¥æœŸ {getSortIcon('production_date')}
            </th>
            <th className="border p-2">ç”¢å“åç¨±</th>
            <th 
              className="border p-2 cursor-pointer hover:bg-gray-200"
              onClick={() => handleSort('quantity')}
            >
              æ•¸é‡ {getSortIcon('quantity')}
            </th>
          </tr>
        </thead>
        <tbody>
          {/* æ¸²æŸ“è³‡æ–™ */}
        </tbody>
      </table>
    </div>
  );
}
```

---

## 3ï¸âƒ£ Product_ID çµ„åˆé‚è¼¯è¨­è¨ˆ

### éœ€æ±‚åˆ†æ

**Product_ID çµ„æˆ**:
```
æ—¥æœŸ + æ©Ÿå°è™Ÿç¢¼ + æ¨¡å…·è™Ÿç¢¼ + ç”Ÿç”¢åºè™Ÿ
ä¾‹å¦‚: 20250310-M01-D05-S123
```

### ğŸ’¡ å»ºè­°ï¼š**å¾Œç«¯çµ„åˆä¸¦å›å‚³ï¼ˆå¼·çƒˆæ¨è–¦ï¼‰**

###  åŸå› åˆ†æ

| è€ƒé‡å› ç´  | å¾Œç«¯çµ„åˆ | å‰ç«¯çµ„åˆ |
|---------|---------|---------|
| **è³‡æ–™ä¸€è‡´æ€§** | çµ±ä¸€é‚è¼¯ | å¯èƒ½ä¸ä¸€è‡´ |
| **ç¶­è­·æ€§** | å–®ä¸€ä¾†æº | å¤šè™•ä¿®æ”¹ |
| **æ•ˆèƒ½** | è¨ˆç®—ä¸€æ¬¡ | æ¯æ¬¡æ¸²æŸ“è¨ˆç®— |
| **å„²å­˜** | å¯å„²å­˜åˆ°DB | ç„¡æ³•å„²å­˜ |
| **æœå°‹** | å¯ç›´æ¥æœå°‹ | ç„¡æ³•æœå°‹ |
| **API å›å‚³** | ç›´æ¥ä½¿ç”¨ | éœ€è¦åŸå§‹æ¬„ä½ |
| **æ¸¬è©¦** | å®¹æ˜“æ¸¬è©¦ | éœ€è¦æ¨¡æ“¬è³‡æ–™ |

### å¯¦ä½œæ–¹æ¡ˆ

#### æ­¥é©Ÿ 1: ä¿®æ”¹è³‡æ–™åº«æ¨¡å‹

```python
# models/record.py

class Record(Base):
    """è³‡æ–™è¨˜éŒ„æ¨¡å‹"""
    __tablename__ = "records"
    
    # ... ç¾æœ‰æ¬„ä½ ...
    
    # P3 å°ˆç”¨æ¬„ä½
    p3_no: Mapped[Optional[str]] = mapped_column(
        String(50),
        nullable=True,
        comment="P3è¿½è¹¤ç·¨è™Ÿ (P3ä½¿ç”¨)"
    )
    
    # æ–°å¢: Product IDï¼ˆP3 ä½¿ç”¨ï¼‰
    product_id: Mapped[Optional[str]] = mapped_column(
        String(100),
        nullable=True,
        comment="ç”¢å“ID: æ—¥æœŸ+æ©Ÿå°+æ¨¡å…·+åºè™Ÿ (P3ä½¿ç”¨)",
        index=True  # å»ºç«‹ç´¢å¼•ä»¥æ”¯æ´æœå°‹
    )
    
    # P3 çµ„æˆæ¬„ä½ï¼ˆå¾ CSV è®€å–ï¼‰
    machine_no: Mapped[Optional[str]] = mapped_column(
        String(20),
        nullable=True,
        comment="æ©Ÿå°è™Ÿç¢¼ (P3ä½¿ç”¨)"
    )
    
    mold_no: Mapped[Optional[str]] = mapped_column(
        String(20),
        nullable=True,
        comment="æ¨¡å…·è™Ÿç¢¼ (P3ä½¿ç”¨)"
    )
    
    production_sequence: Mapped[Optional[str]] = mapped_column(
        String(20),
        nullable=True,
        comment="ç”Ÿç”¢åºè™Ÿ (P3ä½¿ç”¨)"
    )
```

#### æ­¥é©Ÿ 2: å»ºç«‹è³‡æ–™åº«é·ç§»

```bash
cd form-analysis-server/backend
alembic revision -m "add_product_id_and_p3_fields"
```

```python
# migrations/versions/xxxx_add_product_id_and_p3_fields.py

def upgrade():
    # æ–°å¢æ¬„ä½
    op.add_column('records', sa.Column('product_id', sa.String(100), nullable=True))
    op.add_column('records', sa.Column('machine_no', sa.String(20), nullable=True))
    op.add_column('records', sa.Column('mold_no', sa.String(20), nullable=True))
    op.add_column('records', sa.Column('production_sequence', sa.String(20), nullable=True))
    
    # å»ºç«‹ç´¢å¼•
    op.create_index('ix_records_product_id', 'records', ['product_id'])

def downgrade():
    op.drop_index('ix_records_product_id')
    op.drop_column('records', 'production_sequence')
    op.drop_column('records', 'mold_no')
    op.drop_column('records', 'machine_no')
    op.drop_column('records', 'product_id')
```

#### æ­¥é©Ÿ 3: å»ºç«‹ Product ID ç”Ÿæˆå™¨

```python
# services/product_id_generator.py

from datetime import date
from typing import Optional
from app.core.logging import get_logger

logger = get_logger(__name__)


class ProductIDGenerator:
    """Product ID ç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_product_id(
        production_date: Optional[date],
        machine_no: Optional[str],
        mold_no: Optional[str],
        production_sequence: Optional[str],
        separator: str = "-"
    ) -> Optional[str]:
        """
        ç”Ÿæˆ Product ID
        
        æ ¼å¼: YYYYMMDD-{æ©Ÿå°}-{æ¨¡å…·}-{åºè™Ÿ}
        ä¾‹å¦‚: 20250310-M01-D05-S123
        
        Args:
            production_date: ç”Ÿç”¢æ—¥æœŸ
            machine_no: æ©Ÿå°è™Ÿç¢¼
            mold_no: æ¨¡å…·è™Ÿç¢¼
            production_sequence: ç”Ÿç”¢åºè™Ÿ
            separator: åˆ†éš”ç¬¦ï¼ˆé è¨­: -ï¼‰
            
        Returns:
            str: Product IDï¼Œå¦‚æœä»»ä½•å¿…è¦æ¬„ä½ç¼ºå¤±å‰‡è¿”å› None
        """
        try:
            # æª¢æŸ¥å¿…è¦æ¬„ä½
            if not all([production_date, machine_no, mold_no, production_sequence]):
                logger.warning("Product ID ç”Ÿæˆå¤±æ•—: ç¼ºå°‘å¿…è¦æ¬„ä½",
                              has_date=bool(production_date),
                              has_machine=bool(machine_no),
                              has_mold=bool(mold_no),
                              has_sequence=bool(production_sequence))
                return None
            
            # æ ¼å¼åŒ–æ—¥æœŸ
            date_str = production_date.strftime("%Y%m%d")
            
            # æ¸…ç†ä¸¦æ ¼å¼åŒ–å„å€‹éƒ¨åˆ†
            machine_str = str(machine_no).strip().upper()
            mold_str = str(mold_no).strip().upper()
            sequence_str = str(production_sequence).strip()
            
            # çµ„åˆ Product ID
            product_id = separator.join([
                date_str,
                machine_str,
                mold_str,
                sequence_str
            ])
            
            logger.debug("Product ID ç”ŸæˆæˆåŠŸ", product_id=product_id)
            return product_id
            
        except Exception as e:
            logger.error("Product ID ç”Ÿæˆç•°å¸¸", error=str(e))
            return None
    
    @staticmethod
    def parse_product_id(product_id: str, separator: str = "-") -> dict:
        """
        è§£æ Product ID
        
        Args:
            product_id: Product ID å­—ä¸²
            separator: åˆ†éš”ç¬¦
            
        Returns:
            dict: åŒ…å«å„å€‹çµ„æˆéƒ¨åˆ†çš„å­—å…¸
        """
        try:
            parts = product_id.split(separator)
            if len(parts) != 4:
                return {}
            
            date_str, machine, mold, sequence = parts
            
            return {
                'production_date': date_str,
                'machine_no': machine,
                'mold_no': mold,
                'production_sequence': sequence
            }
        except:
            return {}
    
    @staticmethod
    def validate_product_id(product_id: str, separator: str = "-") -> bool:
        """é©—è­‰ Product ID æ ¼å¼"""
        try:
            parts = product_id.split(separator)
            if len(parts) != 4:
                return False
            
            date_str = parts[0]
            # é©—è­‰æ—¥æœŸæ ¼å¼ (YYYYMMDD)
            if len(date_str) != 8 or not date_str.isdigit():
                return False
            
            return True
        except:
            return False


# å»ºç«‹å–®ä¾‹
product_id_generator = ProductIDGenerator()
```

#### æ­¥é©Ÿ 4: ä¿®æ”¹åŒ¯å…¥æœå‹™

```python
# services/import_service.py

from app.services.product_id_generator import product_id_generator

class DataImportService:
    
    async def import_records(
        self, 
        df: pd.DataFrame, 
        data_type: DataType,
        db: AsyncSession
    ) -> Dict[str, Any]:
        """åŒ¯å…¥è³‡æ–™è¨˜éŒ„ï¼ˆè‡ªå‹•ç”Ÿæˆ Product IDï¼‰"""
        
        imported_count = 0
        failed_count = 0
        errors = []
        
        for idx, row in df.iterrows():
            try:
                # æå–åŸºæœ¬æ¬„ä½
                lot_no = row.get('lot_no')
                production_date = row.get('production_date')
                
                # P3 ç‰¹æ®Šè™•ç†
                if data_type == DataType.P3:
                    # æå– P3 çµ„æˆæ¬„ä½
                    machine_no = row.get('æ©Ÿå°è™Ÿç¢¼') or row.get('machine_no')
                    mold_no = row.get('æ¨¡å…·è™Ÿç¢¼') or row.get('mold_no')
                    production_sequence = row.get('ç”Ÿç”¢åºè™Ÿ') or row.get('production_sequence')
                    
                    # è‡ªå‹•ç”Ÿæˆ Product ID
                    product_id = product_id_generator.generate_product_id(
                        production_date=production_date,
                        machine_no=machine_no,
                        mold_no=mold_no,
                        production_sequence=production_sequence
                    )
                    
                    if product_id:
                        logger.info("ç”Ÿæˆ Product ID", 
                                   lot_no=lot_no, 
                                   product_id=product_id)
                    else:
                        logger.warning("Product ID ç”Ÿæˆå¤±æ•—", 
                                      lot_no=lot_no,
                                      row_index=idx)
                    
                    # å»ºç«‹è¨˜éŒ„
                    record = Record(
                        lot_no=lot_no,
                        data_type=data_type,
                        production_date=production_date,
                        p3_no=row.get('P3_No.'),
                        product_name=row.get('product_name'),
                        quantity=row.get('quantity'),
                        notes=row.get('notes'),
                        # P3 å°ˆç”¨æ¬„ä½
                        machine_no=machine_no,
                        mold_no=mold_no,
                        production_sequence=production_sequence,
                        product_id=product_id,  # å„²å­˜ç”Ÿæˆçš„ Product ID
                        additional_data=row.to_dict()
                    )
                else:
                    # P1/P2 è™•ç†
                    record = Record(
                        lot_no=lot_no,
                        data_type=data_type,
                        production_date=production_date,
                        # ... å…¶ä»–æ¬„ä½
                    )
                
                db.add(record)
                imported_count += 1
                
            except Exception as e:
                failed_count += 1
                errors.append({
                    'row_index': idx,
                    'error': str(e)
                })
                logger.error("åŒ¯å…¥è¨˜éŒ„å¤±æ•—", 
                            row_index=idx, 
                            error=str(e))
        
        await db.commit()
        
        return {
            'imported_count': imported_count,
            'failed_count': failed_count,
            'errors': errors
        }
```

#### æ­¥é©Ÿ 5: æ›´æ–°æŸ¥è©¢å›æ‡‰

```python
# api/routes_query.py

class QueryRecord(BaseModel):
    """æŸ¥è©¢è¨˜éŒ„å›æ‡‰æ¨¡å‹"""
    id: str
    lot_no: str
    data_type: str
    production_date: Optional[str]
    created_at: str
    display_name: str
    
    # P3 å°ˆç”¨æ¬„ä½
    p3_no: Optional[str] = None
    product_name: Optional[str] = None
    quantity: Optional[int] = None
    notes: Optional[str] = None
    
    # P3 Product ID ç›¸é—œæ¬„ä½
    product_id: Optional[str] = None  # å¾Œç«¯ç”Ÿæˆä¸¦å›å‚³
    machine_no: Optional[str] = None
    mold_no: Optional[str] = None
    production_sequence: Optional[str] = None
    
    # ... å…¶ä»–æ¬„ä½


@router.get("/p3/search")
async def search_p3_records(...) -> QueryResponse:
    """P3 æœå°‹ï¼ˆåŒ…å« Product IDï¼‰"""
    
    # ... æŸ¥è©¢é‚è¼¯ ...
    
    for record in records:
        query_record = QueryRecord(
            id=str(record.id),
            lot_no=record.lot_no,
            data_type=record.data_type.value,
            production_date=record.production_date.isoformat() if record.production_date else None,
            created_at=record.created_at.isoformat(),
            display_name=record.display_name,
            p3_no=record.p3_no,
            product_name=record.product_name,
            quantity=record.quantity,
            notes=record.notes,
            # Product ID ç›¸é—œæ¬„ä½ï¼ˆå¾Œç«¯çµ„åˆå¥½çš„ï¼‰
            product_id=record.product_id,  # ç›´æ¥è¿”å›
            machine_no=record.machine_no,
            mold_no=record.mold_no,
            production_sequence=record.production_sequence
        )
        query_records.append(query_record)
    
    return QueryResponse(
        total_count=total_count,
        page=page,
        page_size=page_size,
        records=query_records
    )
```

#### æ­¥é©Ÿ 6: æ”¯æ´ Product ID æœå°‹

```python
# api/routes_query.py

@router.get("/p3/search")
async def search_p3_records(
    # ... å…¶ä»–åƒæ•¸ ...
    
    product_id: Optional[str] = Query(None, description="Product IDï¼ˆæ”¯æ´æ¨¡ç³Šæœå°‹ï¼‰"),
    machine_no: Optional[str] = Query(None, description="æ©Ÿå°è™Ÿç¢¼"),
    mold_no: Optional[str] = Query(None, description="æ¨¡å…·è™Ÿç¢¼"),
    production_sequence: Optional[str] = Query(None, description="ç”Ÿç”¢åºè™Ÿ"),
    
    # ...
) -> QueryResponse:
    """P3 æœå°‹ï¼ˆæ”¯æ´ Product IDï¼‰"""
    
    conditions = [Record.data_type == DataType.P3]
    
    # Product ID æœå°‹
    if product_id:
        conditions.append(Record.product_id.ilike(f"%{product_id}%"))
    
    # æ©Ÿå°è™Ÿç¢¼æœå°‹
    if machine_no:
        conditions.append(Record.machine_no.ilike(f"%{machine_no}%"))
    
    # æ¨¡å…·è™Ÿç¢¼æœå°‹
    if mold_no:
        conditions.append(Record.mold_no.ilike(f"%{mold_no}%"))
    
    # ç”Ÿç”¢åºè™Ÿæœå°‹
    if production_sequence:
        conditions.append(Record.production_sequence.ilike(f"%{production_sequence}%"))
    
    # ... å…¶ä»–æŸ¥è©¢é‚è¼¯ ...
```

#### å‰ç«¯ä½¿ç”¨ç¯„ä¾‹

```typescript
// frontend/src/types/record.ts

interface P3Record {
  id: string;
  lot_no: string;
  data_type: 'P3';
  production_date?: string;
  p3_no?: string;
  product_name?: string;
  quantity?: number;
  
  // Product ID ç›¸é—œï¼ˆå¾Œç«¯ç”Ÿæˆä¸¦å›å‚³ï¼‰
  product_id: string;  // ç›´æ¥ä½¿ç”¨
  machine_no?: string;
  mold_no?: string;
  production_sequence?: string;
}

// ç›´æ¥é¡¯ç¤º
function P3RecordRow({ record }: { record: P3Record }) {
  return (
    <tr>
      <td>{record.lot_no}</td>
      <td>{record.product_id}</td>  {/* ç›´æ¥é¡¯ç¤º */}
      <td>{record.machine_no}</td>
      <td>{record.mold_no}</td>
      <td>{record.production_sequence}</td>
    </tr>
  );
}
```

---

## ç¸½çµ

| éœ€æ±‚ | å»ºè­°æ–¹æ¡ˆ | è¤‡é›œåº¦ | å„ªå…ˆç´š |
|------|---------|--------|--------|
| PDF Server å°æ¥ | ç›´æ¥è½‰ç™¼æ¨¡å¼ | ä¸­ | é«˜ |
| P3 æ’åºåŠŸèƒ½ | å¤šæ¬„ä½å‹•æ…‹æ’åº | ä½ | é«˜ |
| Product ID çµ„åˆ | **å¾Œç«¯çµ„åˆ** | ä½ | é«˜ |

###  å¯¦ä½œé †åº

1. **ç¬¬ä¸€éšæ®µ** (1-2å¤©): Product ID ç”Ÿæˆ
   - ä¿®æ”¹è³‡æ–™åº«æ¨¡å‹
   - å¯¦ä½œç”Ÿæˆå™¨
   - æ›´æ–°åŒ¯å…¥é‚è¼¯

2. **ç¬¬äºŒéšæ®µ** (1å¤©): P3 æ’åºåŠŸèƒ½
   - ä¿®æ”¹æŸ¥è©¢ API
   - æ–°å¢æ’åºåƒæ•¸
   - æ›´æ–°å‰ç«¯ UI

3. **ç¬¬ä¸‰éšæ®µ** (2-3å¤©): PDF Server å°æ¥
   - å»ºç«‹å®¢æˆ¶ç«¯æœå‹™
   - æ•´åˆä¸Šå‚³æµç¨‹
   - æ¸¬è©¦å°æ¥

---

**æ–‡æª”ç‰ˆæœ¬**: 2.0  
**æœ€å¾Œæ›´æ–°**: 2025å¹´12æœˆ10æ—¥
